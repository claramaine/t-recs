{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your own metrics\n",
    "This Notebook illustrates how to create your own metrics. At the end of this guide, you'll be able to add new metrics to existing models. For a guide on how to create a new model, please see `advanced-models.ipynb`. In what follows, we assume you are familiar with the main concepts of the framework shown in `complete-guide.ipynb`.\n",
    "\n",
    "Custom metrics allow you to measure any quantity of interest at every timestep of the simulation. For example, at a high level, you might want to track how the diversity of recommendations, user utility, or item popularity evolve over the duration of the simulation. Metrics allow you to do all of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete example\n",
    "\n",
    "The `measure()` method is called before the simulation begins and at the end of each timestep. If the metric has no meaning before the simulation starts, you can simply return `None` from the `measure` method. The argument to the `measure()` method is always the `recommender` model (an instance of `trecs.models.BaseRecmomender`).\n",
    "\n",
    "At the end of the `measure()` method, you should call the `self.observe(value_of_metric)` to actually record the value of the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trecs.metrics import Measurement\n",
    "import numpy as np\n",
    "\n",
    "class SampleMetric(Measurement):\n",
    "    def __init__(self, name=\"sample_metric\", verbose=False):\n",
    "        Measurement.__init__(self, name, verbose)\n",
    "\n",
    "    def measure(self, recommender):\n",
    "        \"\"\"\n",
    "        The purpose of this metric is to calculate the average cosine similarity\n",
    "        between every user profile's and the item the user interacted with. \n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "            recommender: :class:`~models.recommender.BaseRecommender`\n",
    "                Model that inherits from\n",
    "                :class:`~models.recommender.BaseRecommender`.\n",
    "        \"\"\"\n",
    "        similarity = 0\n",
    "        interactions = recommender.interactions\n",
    "        if interactions.size == 0:\n",
    "            self.observe(None) # no interactions yet\n",
    "            return\n",
    "        # interacted items in shape |I| x num_attributes\n",
    "        interacted_items = recommender.predicted_item_attributes[:, interactions].T\n",
    "        item_norm = np.linalg.norm(interacted_items, axis=1)\n",
    "        # user profiles in shape |U| x num_attributes\n",
    "        user_profs = recommender.predicted_user_profiles\n",
    "        user_norm = np.linalg.norm(user_profs, axis=1)\n",
    "        # calculate mean cosine similarity between each user and their item\n",
    "        sim_vals = (interacted_items * user_profs).sum(axis=1) / (item_norm * user_norm)\n",
    "        \n",
    "        # to complete the measurement, call `self.observe(metric_value)`\n",
    "        self.observe(sim_vals.mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating your metric into a simulation\n",
    "\n",
    "To add your metric into a simulation, you can pass an instance of your `Measurement` object into the `metrics` argument when initializing a new simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from trecs.models import ContentFiltering\n",
    "import pandas as pd\n",
    "\n",
    "content_sim = ContentFiltering(num_users=100, num_items=500, measurements=[SampleMetric()])\n",
    "content_sim.run(timesteps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the results of the metric by calling `get_measurements()` on our simulation object. This returns a dictionary that maps the name of the metric to a list of its values. (The `__init__` method of the `Measurement` class defines the default name of our metric, which in this case was `sample_metric`). The dictionary also additionally contains a key-value pair for the timesteps of the simulation.\n",
    "\n",
    "(Pro-tip: use `pd.DataFrame` to visualize the metric alongside the timesteps!) Note that timestep 0 corresponds to the initial state before the simulation starts. The value of our metric is `None` for timestep 0, since no users have any interactions yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_metric</th>\n",
       "      <th>timesteps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9502829304759283</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970409943270234</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.98034821902647</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9830184700808392</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9877600677330426</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.991256236372894</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9902698168114767</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9923935198016904</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9939163865840057</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_metric  timesteps\n",
       "0                 None          0\n",
       "1                  1.0          1\n",
       "2   0.9502829304759283          2\n",
       "3    0.970409943270234          3\n",
       "4     0.98034821902647          4\n",
       "5   0.9830184700808392          5\n",
       "6   0.9877600677330426          6\n",
       "7    0.991256236372894          7\n",
       "8   0.9902698168114767          8\n",
       "9   0.9923935198016904          9\n",
       "10  0.9939163865840057         10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = content_sim.get_measurements()\n",
    "pd.DataFrame({'sample_metric': results['sample_metric'], 'timesteps': results['timesteps']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
