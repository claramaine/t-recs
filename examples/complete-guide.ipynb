{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This Notebook contains an overview of the basic functionality of the simulator. It introduces the simplest ways to get started with the simulator, and it dives into more advanced concepts that will allow you to get a sense of the flexibility of the system. At the end of this guide, you should be able to configure the pre-loaded simulations with custom parameters and metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main components\n",
    "The following diagram provides a birds-eye view of the simulation dynamics. (Note that the diagram does not include content creators, which are optional.)\n",
    "<img src=\"figures/diagram.jpg\" width=500>\n",
    "\n",
    "A simulation needs the following components:\n",
    "\n",
    "- **Users**: agents who interact with each other and with items.\n",
    "- **Model**: agent that defines the behavior of the sociotechnical system. The model mediates the interactions among users and between users and the system.\n",
    "- **Items**: passive components that are served to the users by the model. (Items may come from a fixed catalog or may be dynamically generated by **creators**.)\n",
    "- **Measurements**: modules built into the models which automatically compute information about the system.\n",
    "\n",
    "## Dynamics\n",
    "The following steps are at the heart of the simulations:\n",
    "1. The **model** presents the **users** with some recommended **items**. The recommendations are generated in accordance with the specific recommender system algorithm the model is using (e.g., content filtering, popularity, etc.). The input to the algorithm is based on the model's _prediction_ or _knowledge_ of user preferences.\n",
    "2. The **users** view the items presented by the **model**, and interact with some **items** according to some _actual_ preferences.\n",
    "3. The **model** updates its system state (such as the prediction of user preferences) based on the interactions of **users** with **items**, and it takes some **measurements**.\n",
    "\n",
    "We will see that this framework is very flexible and it can be a generalization of many classic and new models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick start: instantiate a model and run\n",
    "The fastest way to get started is to choose a model, instantiate it with no parameters, and run it for some time steps. Here we run a simple [content filtering recommendation system](https://elucherini.github.io/t-recs/reference/models.html#module-models.content) (please refer to the [BaseRecommender documentation](https://elucherini.github.io/t-recs/reference/models.html#module-models.recommender) for a complete list of class attributes and methods shared by all models, as that information is currently incomplete in the docs of the other pre-loaded models).\n",
    "\n",
    "Content filters infer information about the _attributes_ of users based on their past interactions and recommend items with similar attributes to those of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ContentFiltering\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, InteractionSpread, RecSimilarity, AverageFeatureScoreRange, InteractionSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ContentFiltering instance without arguments\n",
    "default_filtering = ContentFiltering()\n",
    "# add an MSE measurement\n",
    "default_filtering.add_metrics(MSEMeasurement())\n",
    "# Run for 5 time steps\n",
    "default_filtering.run(timesteps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect measurements about the simulation\n",
    "results = default_filtering.get_measurements()\n",
    "\n",
    "print(\"Results of the simulation:\")\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we expand on this minimal example to gain a deeper understanding of what happens under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "As in the ``Quick Start``, if you want to run a simulation, the smallest piece of information you need is the model you want to run. There are a number of pre-loaded models that work out of the box. We continue to use a generic content filtering recommendation system; please see the docs for a [list of already-implemented models](https://elucherini.github.io/t-recs/reference/models.html#).\n",
    "\n",
    "Recall that content filters infer information about the _attributes_ of users based on their past interactions and recommend items with similar attributes to those of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we instantiate the model with no arguments\n",
    "default_filtering = ContentFiltering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we instantiated a content filtering recommender system with default parameters. We print below the default number of users and items in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of users in system: {default_filtering.num_users}\")\n",
    "print(f\"Number of items in system: {default_filtering.num_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model also created a representation for both users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In content filtering, the default model representation of users and items are given by:\")\n",
    "print(f\"- An all-zeros matrix of users of dimension {default_filtering.predicted_user_profiles.shape}\")\n",
    "print(f\"- A randomly generated matrix of items of dimension {default_filtering.predicted_item_attributes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, content filtering supports user profiles of size `|num_users x num_attributes|` and item attributes of size `|num_attributes x num_items|`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set number of users or items\n",
    "We can customize the number of users and items in the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate with a different number of items and users\n",
    "number_of_items = 5000\n",
    "number_of_users = 500\n",
    "filtering = ContentFiltering(num_items = number_of_items, num_users=number_of_users)\n",
    "print(f\"The number of items in the system is now {filtering.num_items}.\")\n",
    "print(f\"The number of users in the system is now {filtering.num_users}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the representations of items and users are set accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The size of item_attributes is {filtering.predicted_item_attributes.shape}.\")\n",
    "print(f\"The size of user_profiles is {filtering.predicted_user_profiles.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User predictions and Items\n",
    "We might also want to define our own representation of users and items. We can do so by defining matrices that satisfy the constraints of the model. The constraints for ContentFiltering (some of which have been mentioned above) are:\n",
    "\n",
    "- User profiles must be of size `|num_users x num_attributes|`.\n",
    "- User profiles are matrices of integers representing the number of interactions of each user with items that have a given attributes. `user_profiles[i, j]` represents the number of interactions user `i` had with items with attribute `j`.\n",
    "- Item attributes must be of size `|num_attributes x num_items|`.\n",
    "- The model doesn't define any constraint on item attributes. If `item_attributes` is binary, then its `[i, j]`th element is 1 if item `j` is attributed attribute `i`; otherwise, it's 0. Item attributes can also be real-valued, representing the probability that each attribute has to describe items.\n",
    "\n",
    "If you're already familiar with Numpy: the model is compatible with `ndarray` and _array_like_ data structures. \n",
    "\n",
    "If you're not familiar with Numpy: the framework provides a random number generator that lets you draw from several distributions (which, in practice, is a thin wrapper around `numpy.random.Generator`). Please refer to the Numpy documentation for a [list of distributions](https://numpy.org/doc/stable/reference/random/generator.html?highlight=generator#distributions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the dimensions small for easy visualization\n",
    "number_of_users = 5\n",
    "number_of_attributes = 10\n",
    "number_of_items = 15\n",
    "# We define user_representation using the standard integer generator in Numpy.\n",
    "# We assume a number of interactions with each attribute in the interval [0,4).\n",
    "user_representation = np.random.randint(4, size=(number_of_users, number_of_attributes))\n",
    "\n",
    "# We define item_representation using the Generator that comes with the framework\n",
    "# We assume a binary matrix with a binomial distribution\n",
    "\n",
    "item_representation = Generator().binomial(\n",
    "    n=1, p=.3, size=(number_of_attributes, number_of_items)\n",
    ")\n",
    "# Note that this is equivalent to:\n",
    "# item_representation = np.random.Generator(np.random.MT19937()).binomial(n=1, p=.5, size=(...))\n",
    "\n",
    "print(f\"User representation (num_users x num_attributes):\\n{str(user_representation)}\\n\")\n",
    "print(f\"Item representation (num_attributes x num_items):\\n{str(item_representation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with custom representations\n",
    "filtering = ContentFiltering(user_representation=user_representation,\n",
    "                             item_representation=item_representation)\n",
    "\n",
    "# Check if they're equivalent\n",
    "is_user_equivalent = \"yes\" if np.array_equal(user_representation, filtering.predicted_user_profiles) else \"no\"\n",
    "is_item_equivalent = \"yes\" if np.array_equal(item_representation, filtering.predicted_item_attributes) else \"no\"\n",
    "print(\"Is user_profiles equivalent to user_representation? %s.\" % is_user_equivalent)\n",
    "print(\"Is item_attributes equivalent to item_representation? %s.\" % is_item_equivalent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also initialize models with `user_representation` and `item_representation` individually. In this case, the representation that has not been initialized will adapt to the size defined by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's only initialize user_profiles\n",
    "filtering = ContentFiltering(user_representation=user_representation)\n",
    "print(\"After initializing user_profiles, the size of item_attributes (and so the number of attributes in the system) adapts automatically to it.\")\n",
    "print(f\"Size of user_profiles, as defined above: {str(filtering.predicted_user_profiles.shape)}.\")\n",
    "print(f\"Size of item_attributes: {str(filtering.predicted_item_attributes.shape)}.\\n\")\n",
    "\n",
    "# The same happens by only initializing item_attributes\n",
    "filtering = ContentFiltering(item_representation=item_representation)\n",
    "print(\"After initializing item_attributes, the size of user_profiles (and so the number of attributes in the system) adapts automatically to it.\")\n",
    "print(f\"Size of item_attributes, as defined above: {str(filtering.predicted_item_attributes.shape)}.\")\n",
    "print(f\"Size of user_profiles: {str(filtering.predicted_user_profiles.shape)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a simulation\n",
    "We can run a simulation for the predefined number of time steps (50), or define our own duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's initialize a model with both user_representation and item_representation defined above\n",
    "filtering = ContentFiltering(user_representation=user_representation,\n",
    "                            item_representation=item_representation)\n",
    "filtering.add_metrics(MSEMeasurement()) # add MSE Measurement\n",
    "# Run the model for the predefined number of timesteps:\n",
    "filtering.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the simulation, we can examine the results of the measurements. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the measurements of all timesteps<=50\n",
    "measurements = filtering.get_measurements()\n",
    "\n",
    "# Measurements can be easily converted to pandas DataFrame objects\n",
    "\n",
    "pd.DataFrame(measurements).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements\n",
    "At each time step of the simulation, measurement modules calculate a quantity based on the system state. An example of such quantity is the mean squared error between the predicted user profiles and the actual user profiles -- that is, how close is the model to predicting the real preferences of the system?\n",
    "\n",
    "It's easy to define new metrics, but in this guide we will use some of the pre-loaded metrics to get a better sense of how they work. For a list of pre-loaded metrics and their descriptions, see the [docs](https://elucherini.github.io/t-recs/reference/metrics.html).\n",
    "\n",
    "### View metrics\n",
    "\n",
    "The metrics monitored are stored in the the model's `metrics` attribute, which contains a list of objects of type [Measurement](https://elucherini.github.io/t-recs/reference/metrics.html#measurement-base-class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The metrics tracked by each model can be examined by printing the `metrics` list.\n",
    "print(\"The system is currently monitoring these metrics:\")\n",
    "print(filtering.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add metrics\n",
    "To **maintain compatibility with pandas**, we suggest to **only add metrics to instances of models that have not been run yet**. This is to avoid having measurements that start at different time steps, resulting in arrays of different length. Feel free to disregard this advice if pandas compatibility is not important to your application.\n",
    "\n",
    "We can instantiate a model, add a new metric, and then run the model.\n",
    "\n",
    "We will add InteractionSpread, which provides a measure of the homogeneity of user interactions in the system as a whole.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the number of items and users to make metric values more reasonable and dimensions distinguishable\n",
    "number_of_items=100\n",
    "number_of_users=50\n",
    "number_of_attributes=20\n",
    "\n",
    "#change the distribution of item attributes so average feature score range can be added later\n",
    "item_representation = Generator().normal(size=(number_of_attributes, number_of_items))\n",
    "filtering = ContentFiltering(num_users=number_of_users, num_items=number_of_items, \n",
    "                             num_attributes=number_of_attributes,\n",
    "                             item_representation=item_representation,\n",
    "                             record_base_state=True)\n",
    "\n",
    "# This method accepts a variable number of metrics\n",
    "filtering.add_metrics(MSEMeasurement(), InteractionSpread())\n",
    "\n",
    "print(\"These are the current metrics:\")\n",
    "print(filtering.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add [RecSimilarity](https://elucherini.github.io/t-recs/reference/metrics.html#recsimilarity), which measures the similarity between interaction patterns for pairs of users. In order to measure Jaccard similarity, we must specify which pairs of users we want to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_pairs = [(u1_idx, u2_idx) for u1_idx in range(filtering.num_users) for u2_idx in range(filtering.num_users) if u1_idx != u2_idx] \n",
    "filtering.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "\n",
    "print(\"These are the current metrics:\")\n",
    "print(filtering.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add average feature score range, a metric for evaluating within list diversity based on the range of item attribute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering.add_metrics(AverageFeatureScoreRange())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we run the model\n",
    "filtering.run(timesteps=5)\n",
    "measurements = filtering.get_measurements()\n",
    "pd.DataFrame(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurements at time step 0 can be undefined (`None`, `NaN`, etc.) because it denotes the measurements before the start of the simulation. MSE is defined at the beginning because the system is initialized with random predictions of the user profiles; in contrast, homogeneity is meaningless before the simulation begins because there are no user interactions to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add diagnostics\n",
    "You can also add diagnostics on the data you are using to calculate your metrics. Diagnostic statistics can be calculated for mean squared error across users. The statistics that are calculated include the mean, standard deviation, median, mean, max, skew, kurtosis, Shapiro-Wilk statistic (for testing distribution normality) and its associated p-value for sample sizes less than 5,000. You can also generate either histograms of the metric distribution, Q-Q plots, or both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_filtering = ContentFiltering()\n",
    "\n",
    "js_pairs = [(u1_idx, u2_idx) for u1_idx in range(default_filtering.num_users) for u2_idx in range(default_filtering.num_users) if u1_idx != u2_idx] \n",
    "\n",
    "# add an MSE measurement\n",
    "default_filtering.add_metrics(MSEMeasurement(diagnostics=True, plot=[\"qq\", \"hist\"]))\n",
    "default_filtering.add_metrics(InteractionSimilarity(pairs=js_pairs, diagnostics=True, plot=[\"hist\"]))\n",
    "\n",
    "default_filtering.run(timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the weird part. Would be better to get this to function the same as \"get_measurements\"\n",
    "mse_diagnostics = default_filtering.metrics[0].get_diagnostics()\n",
    "isim_diagnostics = default_filtering.metrics[1].get_diagnostics()\n",
    "\n",
    "mse_diagnostics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isim_diagnostics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.33it/s]\n"
     ]
    }
   ],
   "source": [
    "number_of_attributes = 10\n",
    "number_of_maj_users = 80\n",
    "number_of_min_users = 20\n",
    "\n",
    "maj_user_representation = np.random.normal(1, 1, size=(number_of_maj_users, number_of_attributes))\n",
    "min_user_representation = np.random.randint(0, 1, size=(number_of_min_users, number_of_attributes))\n",
    "actual_user_representation = np.vstack((maj_user_representation, min_user_representation))\n",
    "\n",
    "filtering = ContentFiltering(actual_user_representation=actual_user_representation, \n",
    "                             num_attributes=number_of_attributes,\n",
    "                             num_items=100)\n",
    "\n",
    "\n",
    "filtering.add_metrics(MSEMeasurement(diagnostics=True, plot=[\"hist\"], split_index=number_of_maj_users+1))\n",
    "filtering.run(timesteps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some applications might require keeping a history of the system's internal state for future processing. This is useful, for example, to study the evolution of predicted user profiles. The framework provides an interface to store and access all the states of each component over time through the `SystemStateModule` interface. Some components are tracked by default, others are added into the individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we instantiated filtering with the option record_base_state=True\n",
    "system_state = filtering.get_system_state()\n",
    "print(\"These are the system state components being monitored:\")\n",
    "print(system_state.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are as many states as the timesteps for which we ran the system + the initial state.\")\n",
    "print(\"For example, the history of predicted_user_profiles has length:\", (len(system_state['predicted_users'])))\n",
    "# the last states correspond to the current state of the components\n",
    "print(\"Furthermore, the last state is in the history of a component corresponds to its current state.\")\n",
    "print(\"Is this true for predicted_user_profiles?\", np.array_equal(system_state['predicted_users'][5], filtering.predicted_user_profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start tracking a new component, you can use the [add_state_variable()](https://elucherini.github.io/t-recs/reference/components.html#base.base_components.SystemStateModule.add_state_variable). Note that state variables can only be monitored if they must inherit from the `BaseComponent` class. Creating new state variables is outside of the scope of this guide, so please refer to the [advanced-models](advanced-models.ipynb) and the [advanced-metrics](advanced-metrics.ipynb) notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Real\" users, \"real\" items\n",
    "Most of what we've seen so far about users refers to the predictions that the system makes about users' preferences and the item attributes. This framework allows for modeling system predictions as well as \"real\" users and items. These \"real\" user and item attributes can be passed into the simulation model; while they remain invisible by the recommender system algorithm, they dictate which items users interact with, and this interaction data is what the recommender system uses to continually retrain.\n",
    "\n",
    "By default, the preference ordering over items for a particular user is defined by the dot product between the item profile and the user profile. You can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider a toy example where all users have a very strong preference for items with the attribute at index 0,\n",
    "# and only the first item has the attribute at index 0\n",
    "\n",
    "# each row is a user\n",
    "real_users = np.array([\n",
    "    [1, 0, 0, 0, 0.7],\n",
    "    [1, 0, 0.1, 0, 0],\n",
    "    [1, 0, 0, 0.2, 0],\n",
    "    [1, 0, 0.5, 0, 0],\n",
    "])\n",
    "\n",
    "# each column is an item\n",
    "real_items = np.array([\n",
    "    [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.1, 0.0, 0.2, 0.0],\n",
    "    [0.0, 0.0, 0.2, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.3],\n",
    "    [0.1, 0.1, 0.2, 0.3, 0.0],\n",
    "])\n",
    "\n",
    "# instantiate content filtering model; note that the system's internal model of\n",
    "# each user's preferences over items will essentially be random\n",
    "# we set the number of items shown to users at each iteration to be 5\n",
    "filtering = ContentFiltering(actual_user_representation=real_users,\n",
    "                             actual_item_representation=real_items,\n",
    "                             num_items_per_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now when we run the model, we can look at the most recent recommendations\n",
    "# and the items the users actually interacted with\n",
    "filtering.run(timesteps=1)\n",
    "print(\"Items shown to each user during the first timestep (row = one user)\")\n",
    "print(filtering.items_shown)\n",
    "\n",
    "print()\n",
    "print(\"Items each user chose to interact with (item at index i represents the item user i chose)\")\n",
    "print(filtering.interactions)\n",
    "\n",
    "print()\n",
    "filtering.run(timesteps=1)\n",
    "print(\"Items shown to each user during the second timestep (row = one user).\")\n",
    "print(\"Note that the the first item shown is item 0, indicating the recommender system has learned the users' preferences.\")\n",
    "print(filtering.items_shown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User interactions with items\n",
    "The Users class also determines how users interact with items. The default behavior is defined in [get_user_feedback()](https://elucherini.github.io/t-recs/reference/components.html#components.users.Users.get_user_feedback). In short, when the system presents items to users, users internally evaluate the items and choose the one item that maximizes the dot product between their own preferences and the item attributes. This default behavior can be overriden to provide a custom model of user-item interaction (for an example, see [DNUsers](https://elucherini.github.io/t-recs/reference/components.html#components.users.DNUsers)).\n",
    "\n",
    "## Model parameters about user interactions\n",
    "Models also provide a few initialization parameters that can be used to tweak the behavior of the model in regards to user interactions. Specifically, models determine the number of items to present users at each iteraction through parameter `num_items_per_iter`. The default is 10 items per user per iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other model parameters\n",
    "Please refer to [the docs](https://elucherini.github.io/algo-segregation/reference/models.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
