{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.spatial.distance import pdist \n",
    "\n",
    "from lenskit.datasets import ML100K, MovieLens\n",
    "from lenskit.algorithms import Recommender, als\n",
    "from lenskit import batch\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ImplicitMF, ImplicitMFLFD, ContentFiltering\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, AverageFeatureScoreRange, RecSimilarity, InteractionSimilarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR = np.random.default_rng(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically just recommends items based on the estimates of user preferences!\n",
    "# this will form the basis of our \"ideal\" recommender\n",
    "class IdealRecommender(ContentFiltering):\n",
    "    def _update_internal_state(self, interactions):\n",
    "        # do not change users_hat! \n",
    "        pass\n",
    "    \n",
    "    def process_new_items(self, new_items):\n",
    "        \"\"\"\n",
    "        Generate zero attributes for new items. Remember,\n",
    "        this doesn't actually matter because the IdealRecommender\n",
    "        uses its perfect score function, not\n",
    "        \"\"\"\n",
    "        num_items = new_items.shape[1]\n",
    "        num_attr = self.items_hat.shape[0]\n",
    "        item_representation = GENERATOR.random((num_attr, num_items))\n",
    "        return item_representation\n",
    "\n",
    "# random recommender - randomly update users at every step\n",
    "class RandomRecommender(ContentFiltering):\n",
    "    def _update_internal_state(self, interactions):\n",
    "        self.items_hat[:, :] = GENERATOR.random(self.items_hat.shape)\n",
    "        self.users_hat[:, :] = GENERATOR.random(self.users_hat.shape)\n",
    "        \n",
    "    def process_new_items(self, new_items):\n",
    "        \"\"\"\n",
    "        Generate random attributes for new items.\n",
    "        \"\"\"\n",
    "        num_items = new_items.shape[1]\n",
    "        num_attr = self.items_hat.shape[0]\n",
    "        item_representation = GENERATOR.random((num_attr, num_items))\n",
    "        return item_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'iterations': 100}\n",
    "# NUM_USERS = 500\n",
    "# NUM_ITEMS= 1000\n",
    "# N_FACTORS = 15\n",
    "\n",
    "NUM_USERS = 100\n",
    "NUM_ITEMS = 10000\n",
    "N_FACTORS = 10\n",
    "NUM_STARTUP = 20\n",
    "NUM_STEPS = 100\n",
    "js_pairs = [(u1_idx, u2_idx) for u1_idx in range(NUM_USERS) for u2_idx in range(NUM_USERS) if u1_idx != u2_idx] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_representation = Generator().binomial(\n",
    "#     n=1, p=.3, size=(NUM_USERS, N_FACTORS)\n",
    "# )\n",
    "\n",
    "# item_representation = Generator().binomial(\n",
    "#     n=1, p=.3, size=(N_FACTORS, NUM_ITEMS)\n",
    "# )\n",
    "# # Initialize with custom representations\n",
    "# filtering = ContentFiltering(user_representation=user_representation,\n",
    "#                             item_representation=item_representation)\n",
    "\n",
    "# filtering.add_metrics(AverageFeatureScoreRange())\n",
    "# filtering.run(10)\n",
    "\n",
    "# filtering.get_measurements()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering.items_hat.all() in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.70it/s]\n",
      "/Users/amywinecoff/Documents/CITP/Research/Github/t-recs/trecs/models/mf.py:262: UserWarning: train_between_steps is set to True. Note that, at each step, this overwrites the MF model with a model fit only to the latest interaction. To avoid this behavior, set train_between_steps to False.\n",
      "  \"train_between_steps is set to True. Note that, at each step, this \"\n",
      "100%|██████████| 100/100 [01:55<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "mf = ImplicitMF(num_users=NUM_USERS, num_items=NUM_ITEMS, num_latent_factors=N_FACTORS, num_items_per_iter=10)\n",
    "                #model_params=model_params)\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "mf.add_metrics(AverageFeatureScoreRange())\n",
    "#mf.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "mf.add_metrics(InteractionSimilarity(pairs=js_pairs))\n",
    "mf.add_state_variable(mf.predicted_scores)\n",
    "mf.add_state_variable(mf.users.actual_user_scores)\n",
    "mf.startup_and_train(NUM_STARTUP)\n",
    "mf.run(timesteps=NUM_STEPS, train_between_steps=True, reset_interactions=False)\n",
    "#mf.run(timesteps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mf.predicted_scores.state_history[0].shape\n",
    "mf.users.actual_user_scores.value.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_step_len = len(str(NUM_STEPS + NUM_STARTUP))\n",
    "\n",
    "for t in range(NUM_STEPS + NUM_STARTUP):\n",
    "\n",
    "    X=mf.predicted_scores.state_history[t].flatten()\n",
    "    Y=mf.users.actual_user_scores.state_history[t].flatten()\n",
    "\n",
    "    # plt.scatter(X, Y)\n",
    "    # plt.figure(figsize=(15, 15))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    fig.set_tight_layout(True)\n",
    "    ax.set(xlim=(-5, 5), ylim=(-5, 5))\n",
    "    ax.set_xlabel(\"Predicted Score\")\n",
    "    ax.set_ylabel(\"Actual Score\")\n",
    "    ax.scatter(X,Y, s=1, alpha=.7)\n",
    "    \n",
    "    step_len=len(str(t))\n",
    "    \n",
    "    num_leading_zeros = final_step_len-step_len\n",
    "    \n",
    "    ext=str('0'*num_leading_zeros) + str(t)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save it & close the figure\n",
    "    filename='/Users/amywinecoff/Documents/CITP/Research/Github/t-recs/examples/scatters/scatter_step'+ext+'.png'\n",
    "    plt.savefig(fname=filename, dpi=96)\n",
    "    plt.gca()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "os.chdir('/Users/amywinecoff/Documents/CITP/Research/Github/t-recs/examples/scatters')\n",
    "#'0'*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()\n",
    "\n",
    "!convert -delay 20 scatter*.png animated_scatter.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(0, 2*np.pi, 0.01)\n",
    "line, = ax.plot(x, np.sin(x))\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_tight_layout(True)\n",
    "ax.set(xlim=(-5, 5), ylim=(-5, 5))\n",
    "ax.set_xlabel(\"Predicted Score\")\n",
    "ax.set_ylabel(\"Actual Score\")\n",
    "# sample 25 creators\n",
    "#creators = np.random.choice(100, 25, replace=False)\n",
    "scat = []\n",
    "\n",
    "\n",
    "def init():\n",
    "    x = mf.predicted_scores.state_history[0].flatten()\n",
    "    y=mf.users.actual_user_scores.state_history[0].flatten()\n",
    "    scat.append(ax.scatter(x,y,  s=1, alpha=.7))\n",
    "    \n",
    "    \n",
    "def animate(t):  \n",
    "    x = mf.predicted_scores.state_history[t].flatten()\n",
    "    y=mf.users.actual_user_scores.state_history[t].flatten()\n",
    "    scat[t].set_data(x, y)\n",
    "    \n",
    "# def animationUpdate(t):\n",
    "#     #x = list(range(N_draws))[:k]\n",
    "#     x = mf.predicted_scores.state_history[0].flatten()\n",
    "#     #y = selectedArm[:k]\n",
    "#     y=mf.users.actual_user_scores.state_history[0].flatten()\n",
    "#     #scat.set_offsets(np.c_[x,y])\n",
    "#     #scat.set_color(colorOfArm[:k])\n",
    "#     #scat.set_facecolor(facecolorArm[:k])\n",
    "#     return scat,\n",
    "# def init():\n",
    "#     X = mf.predicted_scores.state_history[0].flatten()\n",
    "#     Y=mf.users.actual_user_scores.state_history[0].flatten()\n",
    "#     lines.append(ax.scatter(X,Y), s=1, alpha=.7)\n",
    "#     #for c in creators:\n",
    "#      #   blobs.append(ax.plot(group_attr[:1, c], 'o', ls='-', ms=4, markevery=[-1])[0])\n",
    "# def animate(t):\n",
    "#     lines\n",
    "#     num_1 = 0\n",
    "#     num_0 = 0\n",
    "#     for i, c in enumerate(creators):\n",
    "#         lines[i].set_data(np.arange(t+1), group_attr[:t+1, c])\n",
    "#         if group_attr[t, c] >= 1.0:\n",
    "#             num_1 += 1\n",
    "#         elif group_attr[t, c] <= 0.0:\n",
    "#             num_0 += 1\n",
    "#     ax.set_xlabel(f\"Timestep: {t}\\n # of majority-skewed creators: {num_1}, # of minority-skewed creators: {num_0}\")\n",
    "#     return ax\n",
    "anim = FuncAnimation(fig, animate, interval=100, init_func=init)\n",
    "# plt.draw()\n",
    "# plt.show()\n",
    "anim.save('test_animation.gif', writer='imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd = ImplicitMFLFD(num_users=NUM_USERS, num_items=NUM_ITEMS, num_latent_factors=N_FACTORS, num_items_per_iter=10,\n",
    "                     top_n_limit=50) \n",
    "                     # model_params=model_params)\n",
    "mflfd.add_metrics(MSEMeasurement())\n",
    "mflfd.add_metrics(AverageFeatureScoreRange())\n",
    "#mflfd.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "mflfd.add_metrics(InteractionSimilarity(pairs=js_pairs))\n",
    "mflfd.startup_and_train(20)\n",
    "mflfd.run(timesteps=NUM_STEPS, train_between_steps=True, reset_interactions=False)\n",
    "#mflfd.run(timesteps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd_metrics = pd.DataFrame(mflfd.get_measurements())\n",
    "mf_metrics = pd.DataFrame(mf.get_measurements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.actual_user_item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mflfd_metrics = pd.DataFrame(mflfd.get_measurements())\n",
    "mflfd_sim= mflfd_metrics['interaction_similarity'].to_list()[1:]\n",
    "\n",
    "#mf_metrics = pd.DataFrame(mf.get_measurements())\n",
    "mf_sim= mf_metrics['interaction_similarity'].to_list()[1:]\n",
    "# style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "plt.plot(list(range(len(mflfd_sim))), mflfd_sim, marker='', color=palette(0), linewidth=1, alpha=0.9, label='MF-LFD')\n",
    "plt.plot(list(range(len(mf_sim))), mf_sim, marker='', color=palette(1), linewidth=1, alpha=0.9, label='MF')\n",
    "\n",
    "# Add legend\n",
    "#plt.legend(loc=2, ncol=2)\n",
    "plt.legend(loc=1, ncol=1)\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"Randomly Paired Users Interaction Similarity (Repeated)\", loc='center', fontsize=16, fontweight=2)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Jaccard Index\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_mean = np.mean(mf.predicted_scores.value, axis=0)\n",
    "plt.hist(mf_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfd_mean = np.mean(mflfd.predicted_scores.value, axis=0)\n",
    "plt.hist(lfd_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_scores = pd.DataFrame(mf.predicted_scores.value)\n",
    "cols = [f\"item_{c}\" for c in mf_scores.columns]\n",
    "mf_scores.columns = cols\n",
    "#mf_scores.head()\n",
    "mf_scores[\"user\"] = list(range(mf_scores.shape[0]))\n",
    "\n",
    "#list(range(mf_scores.shape[0]))\n",
    "\n",
    "t=pd.wide_to_long(mf_scores, \"item_\", i=\"user\", j=\"item\").reset_index()\n",
    "t.columns = [\"user\", \"item\", \"predicted_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(np.array(mf.predicted_scores.value).flatten(), mf.actual_user_item_scores.flatten())\n",
    "plt.xlabel(\"Predicted Scores\")\n",
    "plt.ylabel(\"Actual Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(mf.actual_user_item_scores, mf.predicted_scores)\n",
    "# from matplotlib.image import NonUniformImage\n",
    "# print(mf.predicted_scores.value.shape)\n",
    "# print(mf.actual_user_item_scores.shape)\n",
    "H, xedges, yedges = np.histogram2d(np.array(mf.predicted_scores.value).flatten(), mf.actual_user_item_scores.flatten())\n",
    "# H = H.T \n",
    "\n",
    "# fig = plt.figure(figsize=(7, 3))\n",
    "# ax = fig.add_subplot(133, title='NonUniformImage: interpolated',aspect='equal')\n",
    "\n",
    "# im = NonUniformImage(ax, interpolation='bilinear')\n",
    "\n",
    "# xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "# ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "# im.set_data(xcenters, ycenters, H)\n",
    "# ax.images.append(im)\n",
    "\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_afsr= mf_metrics['afsr'].to_list()[1:]\n",
    "mflfd_afsr= mflfd_metrics['afsr'].to_list()[1:]\n",
    "\n",
    "# style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "plt.plot(list(range(len(mflfd_afsr))), mflfd_afsr, marker='', color=palette(0), linewidth=1, alpha=0.9, label='MF-LFD')\n",
    "plt.plot(list(range(len(mf_afsr))), mf_afsr, marker='', color=palette(1), linewidth=1, alpha=0.9, label='MF')\n",
    "\n",
    "# Add legend\n",
    "#plt.legend(loc=2, ncol=2)\n",
    "plt.legend(loc=1, ncol=1)\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"AFSR for MF vs. MF-LFD with Repeated Training\", loc='center', fontsize=16, fontweight=2)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"AFSR\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsmall = MovieLens('../../MovieLens/data/ml-latest-small')\n",
    "ratings=mlsmall.ratings\n",
    "\n",
    "#make some fake interactions based on the ratings data\n",
    "ratings[\"interaction\"]=np.where(ratings[\"rating\"]>=4, 1, 0)\n",
    "ratings=ratings[ratings[\"interaction\"]==1]\n",
    "ratings = ratings[['user', 'item']]\n",
    "\n",
    "algo_als = als.ImplicitMF(10, iterations=100)\n",
    "algo_als.fit(ratings)\n",
    "preds_als = batch.predict(algo_als, mlsmall.ratings)\n",
    "#preds_als = pd.merge(preds_als, mlsmall.ratings, on=['user', 'item'])\n",
    "\n",
    "preds_als.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_als.head(30)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(preds_als[\"prediction\"], preds_als[\"rating\"], s=1)\n",
    "plt.xlabel(\"Predicted Interaction Scores\")\n",
    "plt.ylabel(\"Actual Rating Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_item_features = pd.DataFrame(als.item_features_)\n",
    "mflfd_item_features = pd.DataFrame(mflfd.items_hat.T)\n",
    "#mflfd_item_features.head()\n",
    "\n",
    "mf_item_features = pd.DataFrame(mf.items_hat.T)\n",
    "#mf_item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_features(features_df, model_type, color='blue'):\n",
    "    font = {'family' : 'normal',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 12}\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    n_features = list(range(0,10))\n",
    "    fig, axs = plt.subplots(math.ceil(len(n_features)/3), 3, figsize=(20,20))\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                        wspace=0.35)\n",
    "    fig.suptitle('Latent Factors for {}'.format(model_type), size=20)\n",
    "\n",
    "    for idx, n_feature in enumerate(n_features):\n",
    "        r=idx //3\n",
    "        c=idx % 3\n",
    "\n",
    "        #hat = features_df[n_feature].tolist()\n",
    "        features = features_df[n_feature].tolist()\n",
    "        axs[r, c].set_title('Factor {}'.format(n_feature))\n",
    "\n",
    "        #axs[r,c].plot(hat, actual, 'o', color=color);\n",
    "        axs[r,c].hist(features, color=color)\n",
    "\n",
    "    #for ax in axs.flat:\n",
    "    #    ax.set(xlabel='hat representation', ylabel='actual representation')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    #for ax in axs.flat:\n",
    "    #    ax.label_outer()\n",
    "\n",
    "    fig.delaxes(axs[3][1])\n",
    "    fig.delaxes(axs[3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(als_item_features, 'MovieLens MF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(mflfd_item_features, 'MF-LFD', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(mf_item_features, 'MF', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd_d = np.triu(pairwise_distances(mflfd.items_hat.value.T, metric=\"cosine\"))\n",
    "\n",
    "#mflfd_d[mflfd_d ==0] = np.nan\n",
    "#arr[arr == 0] = 'nan' # or use np.nan\n",
    "#mf_d = pairwise_distances(mflfd.items_hat, metric='correlation', force_all_finite=\"allow_nan\")\n",
    "#ml_d = pairwise_distances(als.item_features_.T, metric='correlation', force_all_finite=\"allow_nan\")\n",
    "\n",
    "mflfd_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(mflfd_d)\n",
    "\n",
    "#Y = pdist(mflfd.items_hat, 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(mflfd_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.triu(mflfd_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_item_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_item_attr = mflfd.items_hat[:, mflfd.rec]\n",
    "mflfd_d = pairwise_distances(recommended_item_attr, metric=\"euclidean\")\n",
    "mflfd_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = np.repeat(self.users.user_vector, item_indices.shape[1])\n",
    "# row = row.reshape((self.num_users, -1))\n",
    "# s_filtered = self.predicted_scores.value[row, item_indices]\n",
    "# rec_scores = mflfd.predicted_scores.value[:, mflfd.rec]\n",
    "# rec_scores\n",
    "\n",
    "#top_k_att = self.items_hat.value[:, top_k_recs[:]]\n",
    "rec_array = np.array(mflfd.rec)\n",
    "rec_scores = mflfd.predicted_scores.value[:, rec_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mflfd.predicted_scores.value.shape)\n",
    "print(rec_array.shape)\n",
    "print(rec_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_scores[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd.predicted_scores.value[0,317]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row=np.repeat(100, rec_array.shape[0])\n",
    "#row = row.reshape((mflfd.num_users, -1))\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,np.arange(idx.shape[0])[:,None],idx]\n",
    "\n",
    "mflfd.predicted_scores.value[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanRecDistance(Measurement):\n",
    "    \"\"\"\n",
    "    Measures the average range (across users) of item attributes for items\n",
    "    users were recommended at a time step.\n",
    "\n",
    "    TODO Description\n",
    "\n",
    "    This class inherits from :class:`.Measurement`.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "        verbose: bool (optional, default: False)\n",
    "            If True, enables verbose mode. Disabled by default.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "        Inherited by Measurement: :class:`.Measurement`\n",
    "\n",
    "        name: str (optional, default: \"afsr\")\n",
    "            Name of the measurement component.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"mean_rec_distance\", verbose=False):\n",
    "        Measurement.__init__(self, name, verbose, init_value=None)\n",
    "\n",
    "    def measure(self, recommender, **kwargs):\n",
    "        \"\"\"\n",
    "        Measures the mean of the distance between all pairwise distances between recommendations\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "            recommender: :class:`~models.recommender.BaseRecommender`\n",
    "                Model that inherits from\n",
    "                :class:`~models.recommender.BaseRecommender`.\n",
    "\n",
    "            **kwargs\n",
    "                Keyword arguments, one of which must be `items_shown`, a |U| x\n",
    "                num_items_per_iter matrix that contains the indices of every\n",
    "                item shown to every user at a particular timestep.\n",
    "        \"\"\"\n",
    "        items_shown = kwargs.pop(\"items_shown\", None)\n",
    "        #print(\"interactions {}\".format(interactions))\n",
    "\n",
    "        #assert interactions.size == recommender.num_users\n",
    "        recommended_item_attr = recommender.items_hat[:, items_shown]\n",
    "        #print(\"interacted_item_att shape {}\".format(interacted_item_attr.shape))\n",
    "\n",
    "        if {item for item in recommended_item_attr.flatten()} == {0, 1}:\n",
    "            raise ValueError(\"Mean recommendation distance is not intended for binary features.\")\n",
    "\n",
    "        afsr = np.mean(recommended_item_attr.max(axis=(0, 2)) - recommended_item_attr.min(axis=(0, 2)))\n",
    "\n",
    "        self.observe(afsr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
