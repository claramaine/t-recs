{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ImplicitMF, ImplicitMFLFD\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, AverageFeatureScoreRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 581.08it/s]\n"
     ]
    }
   ],
   "source": [
    "mf = ImplicitMF(num_users=200, num_items=50, num_latent_factors=20)\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "mf.startup_and_train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd = ImplicitMFLFD(num_users=200, num_items=50, num_latent_factors=20)\n",
    "mflfd.add_metrics(MSEMeasurement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 583.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 281.86it/s]\n"
     ]
    }
   ],
   "source": [
    "mflfd.startup_and_train(20)\n",
    "mflfd.run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd.rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.item_indices[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictedScores([[ 1.36333226e-01, -1.66519458e-02,  6.49199936e-02, ...,\n",
       "                  -7.32779306e-03,  1.20038806e-02,  5.92683249e-02],\n",
       "                 [ 4.96087745e-02,  1.37658062e-01,  3.86123711e-02, ...,\n",
       "                  -6.36656763e-02,  3.30936052e-02,  7.93674277e-05],\n",
       "                 [ 2.43081972e-01,  7.76892541e-03,  8.26208732e-02, ...,\n",
       "                   2.51812451e-01,  9.79027408e-02, -6.74336103e-02],\n",
       "                 ...,\n",
       "                 [ 3.92426919e-03,  2.06078771e-01,  1.71795467e-01, ...,\n",
       "                   5.83166856e-03,  7.47863524e-02,  2.05539495e-01],\n",
       "                 [ 1.40650402e-01,  3.74743174e-02,  3.50551931e-02, ...,\n",
       "                   4.57870910e-03, -2.11677300e-03, -2.29767529e-02],\n",
       "                 [ 8.97558951e-03, -9.52487544e-02, -2.03734547e-02, ...,\n",
       "                   4.17621589e-02,  2.46576098e-01,  2.49137211e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_limit=25\n",
    "k=10\n",
    "\n",
    "row = np.repeat(mflfd.users.user_vector, mflfd.item_indices.shape[1])\n",
    "row = row.reshape((mflfd.num_users, -1))\n",
    "s_filtered = mflfd.predicted_scores[row, mflfd.item_indices]\n",
    "\n",
    "negated_scores = -1 * s_filtered  # negate scores so indices go from highest to lowest\n",
    "# break ties using a random score component\n",
    "scores_tiebreak = np.zeros(\n",
    "    negated_scores.shape, dtype=[(\"score\", \"f8\"), (\"random\", \"f8\")]\n",
    ")\n",
    "scores_tiebreak[\"score\"] = negated_scores\n",
    "scores_tiebreak[\"random\"] = mflfd.random_state.random(negated_scores.shape)\n",
    "top_k = scores_tiebreak.argpartition(top_n_limit - 1, order=[\"score\", \"random\"])[:, :top_n_limit]\n",
    "# now we sort within the top k\n",
    "row = np.repeat(mflfd.users.user_vector, top_n_limit).reshape((mflfd.num_users, -1))\n",
    "# again, indices should go from highest to lowest\n",
    "sort_top_k = scores_tiebreak[row, top_k].argsort(order=[\"score\", \"random\"])\n",
    "top_k_recs = mflfd.item_indices[row, top_k[row, sort_top_k]]\n",
    "\n",
    "#dims are attribute, items, users\n",
    "top_k_att = mflfd.items_hat[:, top_k_recs[:]].swapaxes(1,2)\n",
    "# ]  # extract items such that rows go from highest scored to lowest-scored of top-k\n",
    "\n",
    "# #hat_ratings = np.dot(user_features, item_features.T) \n",
    "# if top_n_limit:\n",
    "#     #if constraining by top n, only retain the top n ratings within each user\n",
    "#     ind=np.argpartition(s_filtered,-top_n_limit)[:,-top_n_limit:]\n",
    "#     n_ratings = np.take(s_filtered, ind)\n",
    "# else:\n",
    "#     #if not constraining by top n, retail all item indices for all users. \n",
    "#     #If this is the case, in all_user_recs, recs_idxs should match original_recs_idxs\n",
    "#     ind=np.tile(np.arange(0,len(mflfd.item_features)),(len(mflfd.user_features),1))\n",
    "#     n_ratings = s_filtered\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 25)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test=s_filtered[row, top_k_recs]\n",
    "top_k_recs[user, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.items_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 10, 200)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(top_k_recs.shape)\n",
    "#items_att_filt.swapaxes(1,2)\n",
    "items_att_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_item_att = items_att_filt[:,0, :]\n",
    "top_item_idx = top_k_recs[:, 0].reshape(top_k_recs.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 200) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(top_item_att.shape, top_item_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Items([-0.01123793,  0.00751781, -0.02554887, -0.04741556, -0.01037852,\n",
       "       -0.03844633, -0.05029884,  0.0542907 ,  0.10701629,  0.02496831,\n",
       "        0.04633878,  0.15997014, -0.10993948, -0.12718572,  0.09179639,\n",
       "       -0.1134795 ,  0.01727046,  0.0739141 , -0.04844383, -0.18960749,\n",
       "       -0.0429951 , -0.05942451,  0.12084402, -0.05053055,  0.07371387,\n",
       "       -0.25574536, -0.06095287,  0.09543332, -0.16322751, -0.17180136,\n",
       "        0.14373126,  0.10081025,  0.15051233, -0.02719695,  0.11989134,\n",
       "        0.09782389,  0.0826308 ,  0.21286395, -0.11384116, -0.14549402,\n",
       "       -0.00826814,  0.00204945,  0.00168327, -0.12757597,  0.18901525,\n",
       "        0.15785879,  0.07495036, -0.09718099, -0.20607848,  0.0666113 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.items_hat[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_recs_idx = np.empty([mflfd.users_hat.shape[0], k])\n",
    "# print(all_recs_idx.shape)\n",
    "# print(top_item_idx.shape)\n",
    "# all_recs[:, 0] = top_item_idx[:,None]\n",
    "all_recs_idx = top_k_recs[:,0].reshape(top_k_recs.shape[0],1)\n",
    "top_k_recs[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairwise_distances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-b6a6c12ecc7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0muser_item_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecs_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_item_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cityblock'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'allow_nan'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mmost_distant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pairwise_distances' is not defined"
     ]
    }
   ],
   "source": [
    "#all_recs = np.empty([mflfd.users_hat.shape[0],mflfd.items_hat.shape[1], k])\n",
    "#all_recs_idx = np.empty([mflfd.users_hat.shape[0], k])\n",
    "#top_item_idx = top_k_recs[:, 0]\n",
    "\n",
    "#store the id of the highest predicted item for each user as a start\n",
    "all_recs_idx = top_k_recs[:,0].reshape(top_k_recs.shape[0],1)\n",
    "for idx, user in enumerate(mflfd.users_hat):\n",
    "\n",
    "        user_item_feats = top_k_att[:,:,idx]\n",
    "        user_max_idx = top_k_recs[idx, 0]\n",
    "\n",
    "        #get the top rec and add that as the first item for each user\n",
    "        #user_max = max_idx[idx]\n",
    "        recs_features = mflfd.items_hat[:,user_max_idx]\n",
    "        recs_idxs = user_max_idx\n",
    "        #recs_idxs = [max_idx[idx]]\n",
    "        #recs_preds = [n_ratings[idx][user_max]]\n",
    "        #orig_recs_idxs = [ind[idx, user_max]]\n",
    "        \n",
    "        for rec in range(1,k):\n",
    "            if rec == 1:\n",
    "                #for the second item, just use the first item values\n",
    "                centroid = recs_features\n",
    "            else:\n",
    "                centroid = np.nanmean(recs_features, axis=0)\n",
    "\n",
    "            centroid = centroid.reshape(1, -1)\n",
    "\n",
    "            #set all the previously chosen item features to the centroid, so they will not be selected again\n",
    "            #don't want to just remove rows because it will throw of the indexing\n",
    "            user_item_feats[:, recs_idxs]=centroid\n",
    "\n",
    "            d = pairwise_distances(X=centroid, Y=user_item_feats, metric='cityblock',force_all_finite='allow_nan' )\n",
    "            most_distant = np.argmax(d)\n",
    "\n",
    "            recs_idxs.append(most_distant)\n",
    "            #get the item index from the original array of indices, not the constrained array\n",
    "            #orig_recs_idxs.append(ind[idx, most_distant])\n",
    "            #recs_preds.append(n_ratings[idx][most_distant])\n",
    "\n",
    "            recs_features = np.vstack((recs_features, user_item_feats[most_distant]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 25)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.items_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  7, 11, ..., 35, 20, 26],\n",
       "       [29, 27, 41, ...,  8, 43, 22],\n",
       "       [33, 31, 47, ..., 44, 23, 10],\n",
       "       ...,\n",
       "       [24,  1, 49, ...,  8, 26, 20],\n",
       "       [38,  7, 35, ..., 20, 46, 12],\n",
       "       [44,  7, 21, ...,  5, 14,  8]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def latent_factors_diversification(user_features, item_features, n_recs=10, top_n_limit=None):\n",
    "\n",
    "\n",
    "    hat_ratings = np.dot(user_features, item_features.T) \n",
    "\n",
    "    if top_n_limit:\n",
    "        #if constraining by top n, only retain the top n ratings within each user\n",
    "        ind=np.argpartition(hat_ratings,-top_n_limit)[:,-top_n_limit:]\n",
    "        n_ratings = np.take(hat_ratings, ind)\n",
    "    else:\n",
    "        #if not constraining by top n, retail all item indices for all users. \n",
    "        #If this is the case, in all_user_recs, recs_idxs should match original_recs_idxs\n",
    "        ind=np.tile(np.arange(0,len(item_features)),(len(user_features),1))\n",
    "        n_ratings = hat_ratings\n",
    "\n",
    "\n",
    "\n",
    "    all_user_recs = dict()\n",
    "    \n",
    "    max_idx = np.argmax(n_ratings, axis=1)\n",
    "    top_items=item_features[max_idx]\n",
    "    \n",
    "    all_recs = np.empty([user_features.shape[0],item_features.shape[1], n_recs])\n",
    "    #all_recs = None\n",
    "    \n",
    "\n",
    "    for idx, user in enumerate(user_features):\n",
    "\n",
    "        user_item_feats = item_features[ind[idx]]\n",
    "        user_max_idx = np.argmax(n_ratings[idx])\n",
    "\n",
    "        #get the top rec and add that as the first item for each user\n",
    "        user_max = max_idx[idx]\n",
    "        recs_features = top_items[idx]\n",
    "        recs_idxs = [max_idx[idx]]\n",
    "        recs_preds = [n_ratings[idx][user_max]]\n",
    "        orig_recs_idxs = [ind[idx, user_max]]\n",
    "\n",
    "\n",
    "\n",
    "        for rec in range(1,n_recs):\n",
    "            if rec == 1:\n",
    "                #for the second item, just use the first item values\n",
    "                centroid = recs_features\n",
    "            else:\n",
    "                centroid = np.nanmean(recs_features, axis=0)\n",
    "\n",
    "            centroid = centroid.reshape(1, -1)\n",
    "\n",
    "            #set all the previously chosen item features to the centroid, so they will not be selected again\n",
    "            #don't want to just remove rows because it will throw of the indexing\n",
    "            user_item_feats[recs_idxs]=centroid\n",
    "\n",
    "            d = pairwise_distances(X=centroid, Y=user_item_feats, metric='cityblock',force_all_finite='allow_nan' )\n",
    "            most_distant = np.argmax(d)\n",
    "\n",
    "            recs_idxs.append(most_distant)\n",
    "            #get the item index from the original array of indices, not the constrained array\n",
    "            orig_recs_idxs.append(ind[idx, most_distant])\n",
    "            recs_preds.append(n_ratings[idx][most_distant])\n",
    "\n",
    "            recs_features = np.vstack((recs_features, user_item_feats[most_distant]))\n",
    "\n",
    "        all_recs[idx, :, :]=recs_features\n",
    "            \n",
    "        all_user_recs[idx]={'user_feats': user,\n",
    "                        'original_recs_idx':orig_recs_idxs,\n",
    "                        'recs_idx':recs_idxs,\n",
    "                        'recs_features':recs_features,\n",
    "                        'recs_preds':recs_preds}\n",
    "\n",
    "        \n",
    "    return all_recs, all_user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-25 08:38:47.303962\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
