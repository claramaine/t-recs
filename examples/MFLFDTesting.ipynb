{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ImplicitMF, ImplicitMFLFD\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, AverageFeatureScoreRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = ImplicitMF(num_users=200, num_items=50, num_latent_factors=20)\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "mf.startup_and_train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd = ImplicitMFLFD(num_users=200, num_items=50, num_latent_factors=20)\n",
    "mflfd.add_metrics(MSEMeasurement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 575.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 363.36it/s]\n"
     ]
    }
   ],
   "source": [
    "mflfd.startup_and_train(20)\n",
    "mflfd.run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd.rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.item_indices[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictedScores([[ 1.36333226e-01, -1.66519458e-02,  6.49199936e-02, ...,\n",
       "                  -7.32779306e-03,  1.20038806e-02,  5.92683249e-02],\n",
       "                 [ 4.96087745e-02,  1.37658062e-01,  3.86123711e-02, ...,\n",
       "                  -6.36656763e-02,  3.30936052e-02,  7.93674277e-05],\n",
       "                 [ 2.43081972e-01,  7.76892541e-03,  8.26208732e-02, ...,\n",
       "                   2.51812451e-01,  9.79027408e-02, -6.74336103e-02],\n",
       "                 ...,\n",
       "                 [ 3.92426919e-03,  2.06078771e-01,  1.71795467e-01, ...,\n",
       "                   5.83166856e-03,  7.47863524e-02,  2.05539495e-01],\n",
       "                 [ 1.40650402e-01,  3.74743174e-02,  3.50551931e-02, ...,\n",
       "                   4.57870910e-03, -2.11677300e-03, -2.29767529e-02],\n",
       "                 [ 8.97558951e-03, -9.52487544e-02, -2.03734547e-02, ...,\n",
       "                   4.17621589e-02,  2.46576098e-01,  2.49137211e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_limit=10\n",
    "k=10\n",
    "\n",
    "row = np.repeat(mflfd.users.user_vector, mflfd.item_indices.shape[1])\n",
    "row = row.reshape((mflfd.num_users, -1))\n",
    "s_filtered = mflfd.predicted_scores[row, mflfd.item_indices]\n",
    "\n",
    "negated_scores = -1 * s_filtered  # negate scores so indices go from highest to lowest\n",
    "# break ties using a random score component\n",
    "scores_tiebreak = np.zeros(\n",
    "    negated_scores.shape, dtype=[(\"score\", \"f8\"), (\"random\", \"f8\")]\n",
    ")\n",
    "scores_tiebreak[\"score\"] = negated_scores\n",
    "scores_tiebreak[\"random\"] = mflfd.random_state.random(negated_scores.shape)\n",
    "top_k = scores_tiebreak.argpartition(k - 1, order=[\"score\", \"random\"])[:, :k]\n",
    "# now we sort within the top k\n",
    "row = np.repeat(mflfd.users.user_vector, k).reshape((mflfd.num_users, -1))\n",
    "# again, indices should go from highest to lowest\n",
    "sort_top_k = scores_tiebreak[row, top_k].argsort(order=[\"score\", \"random\"])\n",
    "top_k_recs = mflfd.item_indices[row, top_k[row, sort_top_k]]\n",
    "# ]  # extract items such that rows go from highest scored to lowest-scored of top-k\n",
    "\n",
    "# #hat_ratings = np.dot(user_features, item_features.T) \n",
    "# if top_n_limit:\n",
    "#     #if constraining by top n, only retain the top n ratings within each user\n",
    "#     ind=np.argpartition(s_filtered,-top_n_limit)[:,-top_n_limit:]\n",
    "#     n_ratings = np.take(s_filtered, ind)\n",
    "# else:\n",
    "#     #if not constraining by top n, retail all item indices for all users. \n",
    "#     #If this is the case, in all_user_recs, recs_idxs should match original_recs_idxs\n",
    "#     ind=np.tile(np.arange(0,len(mflfd.item_features)),(len(mflfd.user_features),1))\n",
    "#     n_ratings = s_filtered\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  7, 11, ..., 35, 20, 26],\n",
       "       [29, 27, 41, ...,  8, 43, 22],\n",
       "       [33, 31, 47, ..., 44, 23, 10],\n",
       "       ...,\n",
       "       [24,  1, 49, ...,  8, 26, 20],\n",
       "       [38,  7, 35, ..., 20, 46, 12],\n",
       "       [44,  7, 21, ...,  5, 14,  8]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test=s_filtered[row, top_k_recs]\n",
    "top_k_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = np.empty([mflfd.users_hat.shape[0],mflfd.items_hat.shape[1], k])\n",
    "\n",
    "for idx, user in enumerate(mflfd.users_hat):\n",
    "\n",
    "        user_item_feats = mflfd.items_hat[top_k[idx]]\n",
    "        user_max_idx = np.argmax(n_ratings[idx])\n",
    "\n",
    "        #get the top rec and add that as the first item for each user\n",
    "        user_max = max_idx[idx]\n",
    "        recs_features = top_items[idx]\n",
    "        recs_idxs = [max_idx[idx]]\n",
    "        recs_preds = [n_ratings[idx][user_max]]\n",
    "        orig_recs_idxs = [ind[idx, user_max]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  7, 11, ..., 35, 20, 26],\n",
       "       [29, 27, 41, ...,  8, 43, 22],\n",
       "       [33, 31, 47, ..., 44, 23, 10],\n",
       "       ...,\n",
       "       [24,  1, 49, ...,  8, 26, 20],\n",
       "       [38,  7, 35, ..., 20, 46, 12],\n",
       "       [44,  7, 21, ...,  5, 14,  8]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def latent_factors_diversification(user_features, item_features, n_recs=10, top_n_limit=None):\n",
    "\n",
    "\n",
    "    hat_ratings = np.dot(user_features, item_features.T) \n",
    "\n",
    "    if top_n_limit:\n",
    "        #if constraining by top n, only retain the top n ratings within each user\n",
    "        ind=np.argpartition(hat_ratings,-top_n_limit)[:,-top_n_limit:]\n",
    "        n_ratings = np.take(hat_ratings, ind)\n",
    "    else:\n",
    "        #if not constraining by top n, retail all item indices for all users. \n",
    "        #If this is the case, in all_user_recs, recs_idxs should match original_recs_idxs\n",
    "        ind=np.tile(np.arange(0,len(item_features)),(len(user_features),1))\n",
    "        n_ratings = hat_ratings\n",
    "\n",
    "\n",
    "\n",
    "    all_user_recs = dict()\n",
    "    \n",
    "    max_idx = np.argmax(n_ratings, axis=1)\n",
    "    top_items=item_features[max_idx]\n",
    "    \n",
    "    all_recs = np.empty([user_features.shape[0],item_features.shape[1], n_recs])\n",
    "    #all_recs = None\n",
    "    \n",
    "\n",
    "    for idx, user in enumerate(user_features):\n",
    "\n",
    "        user_item_feats = item_features[ind[idx]]\n",
    "        user_max_idx = np.argmax(n_ratings[idx])\n",
    "\n",
    "        #get the top rec and add that as the first item for each user\n",
    "        user_max = max_idx[idx]\n",
    "        recs_features = top_items[idx]\n",
    "        recs_idxs = [max_idx[idx]]\n",
    "        recs_preds = [n_ratings[idx][user_max]]\n",
    "        orig_recs_idxs = [ind[idx, user_max]]\n",
    "\n",
    "\n",
    "\n",
    "        for rec in range(1,n_recs):\n",
    "            if rec == 1:\n",
    "                #for the second item, just use the first item values\n",
    "                centroid = recs_features\n",
    "            else:\n",
    "                centroid = np.nanmean(recs_features, axis=0)\n",
    "\n",
    "            centroid = centroid.reshape(1, -1)\n",
    "\n",
    "            #set all the previously chosen item features to the centroid, so they will not be selected again\n",
    "            #don't want to just remove rows because it will throw of the indexing\n",
    "            user_item_feats[recs_idxs]=centroid\n",
    "\n",
    "            d = pairwise_distances(X=centroid, Y=user_item_feats, metric='cityblock',force_all_finite='allow_nan' )\n",
    "            most_distant = np.argmax(d)\n",
    "\n",
    "            recs_idxs.append(most_distant)\n",
    "            #get the item index from the original array of indices, not the constrained array\n",
    "            orig_recs_idxs.append(ind[idx, most_distant])\n",
    "            recs_preds.append(n_ratings[idx][most_distant])\n",
    "\n",
    "            recs_features = np.vstack((recs_features, user_item_feats[most_distant]))\n",
    "\n",
    "        all_recs[idx, :, :]=recs_features\n",
    "            \n",
    "        all_user_recs[idx]={'user_feats': user,\n",
    "                        'original_recs_idx':orig_recs_idxs,\n",
    "                        'recs_idx':recs_idxs,\n",
    "                        'recs_features':recs_features,\n",
    "                        'recs_preds':recs_preds}\n",
    "\n",
    "        \n",
    "    return all_recs, all_user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-25 08:38:47.303962\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
