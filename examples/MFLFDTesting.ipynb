{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.spatial.distance import pdist \n",
    "\n",
    "from lenskit.datasets import ML100K, MovieLens\n",
    "from lenskit.algorithms import Recommender, als\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ImplicitMF, ImplicitMFLFD, ContentFiltering\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, AverageFeatureScoreRange, RecSimilarity, InteractionSimilarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR = np.random.default_rng(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically just recommends items based on the estimates of user preferences!\n",
    "# this will form the basis of our \"ideal\" recommender\n",
    "class IdealRecommender(ContentFiltering):\n",
    "    def _update_internal_state(self, interactions):\n",
    "        # do not change users_hat! \n",
    "        pass\n",
    "    \n",
    "    def process_new_items(self, new_items):\n",
    "        \"\"\"\n",
    "        Generate zero attributes for new items. Remember,\n",
    "        this doesn't actually matter because the IdealRecommender\n",
    "        uses its perfect score function, not\n",
    "        \"\"\"\n",
    "        num_items = new_items.shape[1]\n",
    "        num_attr = self.items_hat.shape[0]\n",
    "        item_representation = GENERATOR.random((num_attr, num_items))\n",
    "        return item_representation\n",
    "\n",
    "# random recommender - randomly update users at every step\n",
    "class RandomRecommender(ContentFiltering):\n",
    "    def _update_internal_state(self, interactions):\n",
    "        self.items_hat[:, :] = GENERATOR.random(self.items_hat.shape)\n",
    "        self.users_hat[:, :] = GENERATOR.random(self.users_hat.shape)\n",
    "        \n",
    "    def process_new_items(self, new_items):\n",
    "        \"\"\"\n",
    "        Generate random attributes for new items.\n",
    "        \"\"\"\n",
    "        num_items = new_items.shape[1]\n",
    "        num_attr = self.items_hat.shape[0]\n",
    "        item_representation = GENERATOR.random((num_attr, num_items))\n",
    "        return item_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'iterations': 100}\n",
    "# NUM_USERS = 500\n",
    "# NUM_ITEMS= 1000\n",
    "# N_FACTORS = 15\n",
    "\n",
    "NUM_USERS = 100\n",
    "NUM_ITEMS = 100\n",
    "N_FACTORS = 20\n",
    "NUM_STEPS = 150\n",
    "js_pairs = [(u1_idx, u2_idx) for u1_idx in range(NUM_USERS) for u2_idx in range(NUM_USERS) if u1_idx != u2_idx] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "AFSR is not intended for binary features.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-82cc990f22e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfiltering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAverageFeatureScoreRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfiltering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfiltering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_measurements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CITP/Research/Github/t-recs/trecs/models/recommender.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, timesteps, startup, train_between_steps, random_items_per_iter, vary_random_items_per_iter, repeated_items, no_new_items)\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_between_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstartup_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_new_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CITP/Research/Github/t-recs/trecs/models/recommender.py\u001b[0m in \u001b[0;36mmeasure_content\u001b[0;34m(self, interactions, items_shown, step)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \"\"\"\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_shown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitems_shown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CITP/Research/Github/t-recs/trecs/metrics/measurement.py\u001b[0m in \u001b[0;36mmeasure\u001b[0;34m(self, recommender, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m#if {item for item in recommended_item_attr.flatten()} == {0, 1}:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecommended_item_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AFSR is not intended for binary features.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mafsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommended_item_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrecommended_item_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: AFSR is not intended for binary features."
     ]
    }
   ],
   "source": [
    "user_representation = Generator().binomial(\n",
    "    n=1, p=.3, size=(NUM_USERS, N_FACTORS)\n",
    ")\n",
    "\n",
    "item_representation = Generator().binomial(\n",
    "    n=1, p=.3, size=(N_FACTORS, NUM_ITEMS)\n",
    ")\n",
    "# Initialize with custom representations\n",
    "filtering = ContentFiltering(user_representation=user_representation,\n",
    "                            item_representation=item_representation)\n",
    "\n",
    "filtering.add_metrics(AverageFeatureScoreRange())\n",
    "filtering.run(10)\n",
    "\n",
    "filtering.get_measurements()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering.items_hat.all() in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = ImplicitMF(num_users=NUM_USERS, num_items=NUM_ITEMS, num_latent_factors=N_FACTORS, num_items_per_iter=10) \n",
    "                #model_params=model_params)\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "mf.add_metrics(AverageFeatureScoreRange())\n",
    "#mf.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "mf.add_metrics(InteractionSimilarity(pairs=js_pairs))\n",
    "mf.startup_and_train(20)\n",
    "mf.run(timesteps=NUM_STEPS, train_between_steps=True, reset_interactions=False)\n",
    "#mf.run(timesteps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd = ImplicitMFLFD(num_users=NUM_USERS, num_items=NUM_ITEMS, num_latent_factors=N_FACTORS, num_items_per_iter=10) \n",
    "                     # model_params=model_params)\n",
    "mflfd.add_metrics(MSEMeasurement())\n",
    "mflfd.add_metrics(AverageFeatureScoreRange())\n",
    "#mflfd.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "mflfd.add_metrics(InteractionSimilarity(pairs=js_pairs))\n",
    "mflfd.startup_and_train(20)\n",
    "mflfd.run(timesteps=NUM_STEPS, train_between_steps=True, reset_interactions=False)\n",
    "#mflfd.run(timesteps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd_metrics = pd.DataFrame(mflfd.get_measurements())\n",
    "mf_metrics = pd.DataFrame(mf.get_measurements())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd_metrics.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mflfd_metrics = pd.DataFrame(mflfd.get_measurements())\n",
    "mflfd_sim= mflfd_metrics['interaction_similarity'].to_list()[1:]\n",
    "\n",
    "#mf_metrics = pd.DataFrame(mf.get_measurements())\n",
    "mf_sim= mf_metrics['interaction_similarity'].to_list()[1:]\n",
    "# style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "plt.plot(list(range(len(mflfd_sim))), mflfd_sim, marker='', color=palette(0), linewidth=1, alpha=0.9, label='MF-LFD')\n",
    "plt.plot(list(range(len(mf_sim))), mf_sim, marker='', color=palette(1), linewidth=1, alpha=0.9, label='MF')\n",
    "\n",
    "# Add legend\n",
    "#plt.legend(loc=2, ncol=2)\n",
    "plt.legend(loc=1, ncol=1)\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"Random Users Interaction Similarity with Repeated Training\", loc='center', fontsize=16, fontweight=2)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Jaccard Index\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_afsr= mf_metrics['afsr'].to_list()[1:]\n",
    "mflfd_afsr= mflfd_metrics['afsr'].to_list()[1:]\n",
    "\n",
    "# style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# create a color palette\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "plt.plot(list(range(len(mflfd_afsr))), mflfd_afsr, marker='', color=palette(0), linewidth=1, alpha=0.9, label='MF-LFD')\n",
    "plt.plot(list(range(len(mf_afsr))), mf_afsr, marker='', color=palette(1), linewidth=1, alpha=0.9, label='MF')\n",
    "\n",
    "# Add legend\n",
    "#plt.legend(loc=2, ncol=2)\n",
    "plt.legend(loc=1, ncol=1)\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"AFSR for MF vs. MF-LFD with Repeated Training\", loc='center', fontsize=16, fontweight=2)\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"AFSR\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsmall = MovieLens('../../t-recs-experiments/data/ml-latest-small')\n",
    "ratings = mlsmall.ratings[['user', 'item']]\n",
    "\n",
    "als = als.ImplicitMF(10, iterations=100)\n",
    "als.fit(ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_item_features = pd.DataFrame(als.item_features_)\n",
    "mflfd_item_features = pd.DataFrame(mflfd.items_hat.T)\n",
    "#mflfd_item_features.head()\n",
    "\n",
    "mf_item_features = pd.DataFrame(mf.items_hat.T)\n",
    "#mf_item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_features(features_df, model_type, color='blue'):\n",
    "    font = {'family' : 'normal',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 12}\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    n_features = list(range(0,10))\n",
    "    fig, axs = plt.subplots(math.ceil(len(n_features)/3), 3, figsize=(20,20))\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                        wspace=0.35)\n",
    "    fig.suptitle('Latent Factors for {}'.format(model_type), size=20)\n",
    "\n",
    "    for idx, n_feature in enumerate(n_features):\n",
    "        r=idx //3\n",
    "        c=idx % 3\n",
    "\n",
    "        #hat = features_df[n_feature].tolist()\n",
    "        features = features_df[n_feature].tolist()\n",
    "        axs[r, c].set_title('Factor {}'.format(n_feature))\n",
    "\n",
    "        #axs[r,c].plot(hat, actual, 'o', color=color);\n",
    "        axs[r,c].hist(features, color=color)\n",
    "\n",
    "    #for ax in axs.flat:\n",
    "    #    ax.set(xlabel='hat representation', ylabel='actual representation')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    #for ax in axs.flat:\n",
    "    #    ax.label_outer()\n",
    "\n",
    "    fig.delaxes(axs[3][1])\n",
    "    fig.delaxes(axs[3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(als_item_features, 'MovieLens MF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(mflfd_item_features, 'MF-LFD', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(mf_item_features, 'MF', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd_d = np.triu(pairwise_distances(mflfd.items_hat, metric=\"euclidean\"))\n",
    "\n",
    "mflfd_d[mflfd_d ==0] = np.nan\n",
    "#arr[arr == 0] = 'nan' # or use np.nan\n",
    "#mf_d = pairwise_distances(mflfd.items_hat, metric='correlation', force_all_finite=\"allow_nan\")\n",
    "#ml_d = pairwise_distances(als.item_features_.T, metric='correlation', force_all_finite=\"allow_nan\")\n",
    "np.nanmean(mflfd_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Y = pdist(mflfd.items_hat, 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.triu(mflfd_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_item_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_item_attr = mflfd.items_hat[:, mflfd.rec]\n",
    "mflfd_d = pairwise_distances(recommended_item_attr, metric=\"euclidean\")\n",
    "mflfd_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanRecDistance(Measurement):\n",
    "    \"\"\"\n",
    "    Measures the average range (across users) of item attributes for items\n",
    "    users were recommended at a time step.\n",
    "\n",
    "    TODO Description\n",
    "\n",
    "    This class inherits from :class:`.Measurement`.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "        verbose: bool (optional, default: False)\n",
    "            If True, enables verbose mode. Disabled by default.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "        Inherited by Measurement: :class:`.Measurement`\n",
    "\n",
    "        name: str (optional, default: \"afsr\")\n",
    "            Name of the measurement component.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"mean_rec_distance\", verbose=False):\n",
    "        Measurement.__init__(self, name, verbose, init_value=None)\n",
    "\n",
    "    def measure(self, recommender, **kwargs):\n",
    "        \"\"\"\n",
    "        Measures the mean of the distance between all pairwise distances between recommendations\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "            recommender: :class:`~models.recommender.BaseRecommender`\n",
    "                Model that inherits from\n",
    "                :class:`~models.recommender.BaseRecommender`.\n",
    "\n",
    "            **kwargs\n",
    "                Keyword arguments, one of which must be `items_shown`, a |U| x\n",
    "                num_items_per_iter matrix that contains the indices of every\n",
    "                item shown to every user at a particular timestep.\n",
    "        \"\"\"\n",
    "        items_shown = kwargs.pop(\"items_shown\", None)\n",
    "        #print(\"interactions {}\".format(interactions))\n",
    "\n",
    "        #assert interactions.size == recommender.num_users\n",
    "        recommended_item_attr = recommender.items_hat[:, items_shown]\n",
    "        #print(\"interacted_item_att shape {}\".format(interacted_item_attr.shape))\n",
    "\n",
    "        if {item for item in recommended_item_attr.flatten()} == {0, 1}:\n",
    "            raise ValueError(\"Mean recommendation distance is not intended for binary features.\")\n",
    "\n",
    "        afsr = np.mean(recommended_item_attr.max(axis=(0, 2)) - recommended_item_attr.min(axis=(0, 2)))\n",
    "\n",
    "        self.observe(afsr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
