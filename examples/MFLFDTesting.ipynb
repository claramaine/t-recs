{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.spatial.distance import pdist \n",
    "import os\n",
    "\n",
    "from lenskit.datasets import ML100K, MovieLens\n",
    "from lenskit.algorithms import Recommender, als\n",
    "from lenskit import batch, topn\n",
    "\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ImplicitMF, ImplicitMFLFD, ContentFiltering\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, AverageFeatureScoreRange, RecSimilarity, InteractionSimilarity, Measurement\n",
    "from trecs.components import Users\n",
    "import trecs.matrix_ops as mo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically just recommends items based on the estimates of user preferences!\n",
    "# this will form the basis of our \"ideal\" recommender\n",
    "class IdealRecommender(ContentFiltering):\n",
    "    def _update_internal_state(self, interactions):\n",
    "        # do not change users_hat! \n",
    "        pass\n",
    "    \n",
    "    def process_new_items(self, new_items):\n",
    "        \"\"\"\n",
    "        Generate zero attributes for new items. Remember,\n",
    "        this doesn't actually matter because the IdealRecommender\n",
    "        uses its perfect score function, not\n",
    "        \"\"\"\n",
    "        num_items = new_items.shape[1]\n",
    "        num_attr = self.items_hat.shape[0]\n",
    "        item_representation = GENERATOR.random((num_attr, num_items))\n",
    "        return item_representation\n",
    "\n",
    "# random recommender - randomly update users at every step\n",
    "class RandomRecommender(ContentFiltering):\n",
    "    def _update_internal_state(self, interactions):\n",
    "        self.items_hat[:, :] = GENERATOR.random(self.items_hat.shape)\n",
    "        self.users_hat[:, :] = GENERATOR.random(self.users_hat.shape)\n",
    "        \n",
    "    def process_new_items(self, new_items):\n",
    "        \"\"\"\n",
    "        Generate random attributes for new items.\n",
    "        \"\"\"\n",
    "        num_items = new_items.shape[1]\n",
    "        num_attr = self.items_hat.shape[0]\n",
    "        item_representation = GENERATOR.random((num_attr, num_items))\n",
    "        return item_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShownMedianPrediction(Measurement):\n",
    "    \"\"\"\n",
    "    Measures the median predicted value of recommended items.\n",
    "\n",
    "    TODO Description\n",
    "\n",
    "    This class inherits from :class:`.Measurement`.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "        verbose: bool (optional, default: False)\n",
    "            If True, enables verbose mode. Disabled by default.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "        Inherited by Measurement: :class:`.Measurement`\n",
    "\n",
    "        name: str (optional, default: \"afsr\")\n",
    "            Name of the measurement component.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"shown_median_prediction\", verbose=False):\n",
    "        Measurement.__init__(self, name, verbose, init_value=None)\n",
    "\n",
    "    def measure(self, recommender, **kwargs):\n",
    "        \"\"\"\n",
    "        Measures the mean of the distance between all pairwise distances between recommendations\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "            recommender: :class:`~models.recommender.BaseRecommender`\n",
    "                Model that inherits from\n",
    "                :class:`~models.recommender.BaseRecommender`.\n",
    "\n",
    "            **kwargs\n",
    "                Keyword arguments, one of which must be `items_shown`, a |U| x\n",
    "                num_items_per_iter matrix that contains the indices of every\n",
    "                item shown to every user at a particular timestep.\n",
    "        \"\"\"\n",
    "        items_shown = kwargs.pop(\"items_shown\", None)\n",
    "        predicted_shown_vals=recommender.predicted_scores.value[np.expand_dims(np.arange(recommender.predicted_scores.value.shape[0]), -1), \n",
    "                                                items_shown]\n",
    "\n",
    "        shown_median=np.median(predicted_shown_vals)\n",
    "\n",
    "        self.observe(shown_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractedMedianPrediction(Measurement):\n",
    "    \"\"\"\n",
    "    Measures the median predicted value of recommended items.\n",
    "\n",
    "    TODO Description\n",
    "\n",
    "    This class inherits from :class:`.Measurement`.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "        verbose: bool (optional, default: False)\n",
    "            If True, enables verbose mode. Disabled by default.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "        Inherited by Measurement: :class:`.Measurement`\n",
    "\n",
    "        name: str (optional, default: \"afsr\")\n",
    "            Name of the measurement component.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"interacted_median_prediction\", verbose=False):\n",
    "        Measurement.__init__(self, name, verbose, init_value=None)\n",
    "\n",
    "    def measure(self, recommender, **kwargs):\n",
    "        \"\"\"\n",
    "        Measures the mean of the distance between all pairwise distances between recommendations\n",
    "\n",
    "        Parameters\n",
    "        ------------\n",
    "            recommender: :class:`~models.recommender.BaseRecommender`\n",
    "                Model that inherits from\n",
    "                :class:`~models.recommender.BaseRecommender`.\n",
    "\n",
    "            **kwargs\n",
    "                Keyword arguments, one of which must be `items_shown`, a |U| x\n",
    "                num_items_per_iter matrix that contains the indices of every\n",
    "                item shown to every user at a particular timestep.\n",
    "        \"\"\"\n",
    "        interactions = kwargs.pop(\"interactions\", None)\n",
    "        \n",
    "        if interactions is None:\n",
    "            raise ValueError(\n",
    "                \"interactions must be passed in to InteractedMedianPrediction `measure` \"\n",
    "                \"method as a keyword argument\"\n",
    "            )\n",
    "        predicted_int_vals=recommender.predicted_scores.value[np.expand_dims(np.arange(recommender.predicted_scores.value.shape[0]), -1), \n",
    "                                                interactions]\n",
    "\n",
    "        int_median=np.median(predicted_int_vals)\n",
    "\n",
    "        self.observe(int_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanRecDistance(Measurement):\n",
    "    \"\"\"\n",
    "    Cacluates the mean distance between items in each users' recommendation list based on their item attributes\n",
    "    This class inherits from :class:`.Measurement`.\n",
    "    Parameters\n",
    "    -----------\n",
    "        verbose: bool (optional, default: False)\n",
    "            If True, enables verbose mode. Disabled by default.\n",
    "    Attributes\n",
    "    -----------\n",
    "        Inherited by Measurement: :class:`.Measurement`\n",
    "        name: str (optional, default: \"mean_rec_distance\")\n",
    "            Name of the measurement component.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"mean_rec_distance\", verbose=False, distance_metric=\"cosine\"):\n",
    "        Measurement.__init__(self, name, verbose, init_value=None)\n",
    "        self.distance_metric=distance_metric\n",
    "\n",
    "    def measure(self, recommender, **kwargs):\n",
    "        \"\"\"\n",
    "        TODO\n",
    "        Parameters\n",
    "        ------------\n",
    "            recommender: :class:`~models.recommender.BaseRecommender`\n",
    "                Model that inherits from\n",
    "                :class:`~models.recommender.BaseRecommender`.\n",
    "            **kwargs\n",
    "                Keyword arguments, one of which must be `items_shown`, a |U| x\n",
    "                num_items_per_iter matrix that contains the indices of every\n",
    "                item shown to every user at a particular timestep.\n",
    "        \"\"\"\n",
    "        items_shown = kwargs.pop(\"items_shown\", None)\n",
    "\n",
    "        recommended_item_attr = recommender.items_hat.value[:, items_shown]\n",
    "        \n",
    "        user_distances = []\n",
    "        \n",
    "        for userid in range(recommended_item_attr.shape[1]):\n",
    "            user_rec_attr=recommended_item_attr[:,userid,:]\n",
    "\n",
    "            #take the upper triangle to reduce duplicates\n",
    "            upper = np.triu(pairwise_distances(user_rec_attr.T, metric=self.distance_metric))\n",
    "            #replace 0s with nans so the distance to self doesn't get included\n",
    "            upper = np.where(upper==0, np.nan, upper)\n",
    "\n",
    "            mean_rec_distance = np.nanmean(upper)\n",
    "            user_distances.append(mean_rec_distance)\n",
    "        \n",
    "        mean_rec_distance=np.mean(np.array(user_distances))\n",
    "        \n",
    "        self.observe(mean_rec_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'iterations': 100}\n",
    "# NUM_USERS = 500\n",
    "# NUM_ITEMS= 1000\n",
    "# N_FACTORS = 15\n",
    "\n",
    "NUM_USERS = 100\n",
    "NUM_ITEMS = 1250\n",
    "N_FACTORS = 10\n",
    "NUM_STARTUP = 20\n",
    "NUM_STEPS = 105\n",
    "js_pairs = [(u1_idx, u2_idx) for u1_idx in range(NUM_USERS) for u2_idx in range(NUM_USERS) if u1_idx != u2_idx] \n",
    "\n",
    "# user_representation = Generator().binomial(\n",
    "#     n=1, p=.3, size=(NUM_USERS, N_FACTORS)\n",
    "# )\n",
    "\n",
    "# item_representation = Generator().binomial(\n",
    "#     n=1, p=.3, size=(N_FACTORS, NUM_ITEMS)\n",
    "# )\n",
    "SCORE_FN=mo.inner_product\n",
    "SCORE_FN.__defaults__ = (False, False)\n",
    "\n",
    "GEN = np.random.default_rng(1234)\n",
    "ACTUAL_USER_PROFILES=GEN.normal(size=(NUM_USERS, N_FACTORS))\n",
    "ACTUAL_ITEM_ATTRIBUTES=GEN.normal(size=(N_FACTORS, NUM_ITEMS))\n",
    "\n",
    "USERS = Users(repeat_interactions=False, actual_user_profiles=ACTUAL_USER_PROFILES, \n",
    "              score_fn=SCORE_FN)\n",
    "\n",
    "# user_rep = GENERATOR.normal(size=(NUM_USERS, N_FACTORS))\n",
    "# #USERS = Users(size=(NUM_USERS, N_FACTORS), repeat_interactions=False)\n",
    "# u = Users(actual_user_scores = user_rep, size=(NUM_USERS, N_FACTORS), num_users=NUM_USERS, repeat_interactions=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.85it/s]\n",
      "/Users/amywinecoff/Documents/CITP/Research/Github/t-recs/trecs/models/mf.py:262: UserWarning: train_between_steps is set to True. Note that, at each step, this overwrites the MF model with a model fit only to the latest interaction. To avoid this behavior, set train_between_steps to False.\n",
      "  \"train_between_steps is set to True. Note that, at each step, this \"\n",
      "100%|██████████| 105/105 [01:43<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "#mf = ImplicitMF(num_users=NUM_USERS, num_items=NUM_ITEMS, num_latent_factors=N_FACTORS, num_items_per_iter=10,\n",
    "#                model_params=model_params)\n",
    "\n",
    "mf = ImplicitMF(actual_user_representation=Users(repeat_interactions=False, size=(NUM_USERS, N_FACTORS)), \n",
    "                num_items=NUM_ITEMS, num_latent_factors=N_FACTORS, num_items_per_iter=10,\n",
    "                model_params=model_params)\n",
    "\n",
    "#print(mf.num_items)\n",
    "#\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "mf.add_metrics(AverageFeatureScoreRange())\n",
    "#mf.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "mf.add_metrics(InteractionSimilarity(pairs=js_pairs))\n",
    "mf.add_metrics(ShownMedianPrediction())\n",
    "mf.add_metrics(InteractedMedianPrediction())\n",
    "mf.add_metrics(MeanRecDistance())\n",
    "\n",
    "mf.add_state_variable(mf.predicted_scores)\n",
    "mf.add_state_variable(mf.users.actual_user_scores)\n",
    "mf.startup_and_train(NUM_STARTUP)\n",
    "#mf.users.repeat_interactions=False\n",
    "mf.run(timesteps=NUM_STEPS, train_between_steps=True, reset_interactions=False)\n",
    "#mf.run(timesteps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.60it/s]\n",
      "/Users/amywinecoff/Documents/CITP/Research/Github/t-recs/trecs/models/mf.py:262: UserWarning: train_between_steps is set to True. Note that, at each step, this overwrites the MF model with a model fit only to the latest interaction. To avoid this behavior, set train_between_steps to False.\n",
      "  \"train_between_steps is set to True. Note that, at each step, this \"\n",
      "100%|██████████| 105/105 [02:11<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "mflfd = ImplicitMFLFD(actual_user_representation=Users(repeat_interactions=False, size=(NUM_USERS, N_FACTORS)), \n",
    "                      num_items=NUM_ITEMS, num_latent_factors=N_FACTORS, num_items_per_iter=10,\n",
    "                     top_n_limit=50, model_params=model_params)\n",
    "\n",
    "mflfd.add_metrics(MSEMeasurement())\n",
    "mflfd.add_metrics(AverageFeatureScoreRange())\n",
    "#mflfd.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "mflfd.add_metrics(InteractionSimilarity(pairs=js_pairs))\n",
    "mflfd.add_metrics(ShownMedianPrediction())\n",
    "mflfd.add_metrics(InteractedMedianPrediction())\n",
    "mflfd.add_metrics(MeanRecDistance())\n",
    "\n",
    "mflfd.add_state_variable(mflfd.predicted_scores)\n",
    "mflfd.add_state_variable(mflfd.users.actual_user_scores)\n",
    "mflfd.startup_and_train(20)\n",
    "mflfd.run(timesteps=NUM_STEPS, train_between_steps=True, reset_interactions=False)\n",
    "#mflfd.run(timesteps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.users.actual_user_scores.value[3,2]\n",
    "print(mf.users.actual_user_scores.shape)\n",
    "print(mf.users.actual_user_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf.users.actual_user_scores.shape[1]\n",
    "#print(mf.users.actual_user_profiles.value[3,:])\n",
    "#print(mf.actual_item_attributes[:,2])\n",
    "m=np.dot(mf.users.actual_user_profiles.value, mf.actual_item_attributes)\n",
    "pd.DataFrame(m).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mf.users.actual_user_scores.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.681182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.744136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.691402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.708399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.663785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.762712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.753711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.729181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.754841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nrecs      ndcg\n",
       "user                  \n",
       "0     1250.0  0.765192\n",
       "1     1250.0  0.681182\n",
       "2     1250.0  0.744136\n",
       "3     1250.0  0.691402\n",
       "4     1250.0  0.708399\n",
       "5     1250.0  0.663785\n",
       "6     1250.0  0.762712\n",
       "7     1250.0  0.753711\n",
       "8     1250.0  0.729181\n",
       "9     1250.0  0.754841"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#col_names = [str(c) for c in mf.users.actual_user_scores.shape[1]]\n",
    "cols = [f\"item_{c}\" for c in range(mf.users.actual_user_scores.shape[1])]\n",
    "actual_scores_df=pd.DataFrame(np.dot(mf.users.actual_user_profiles.value, mf.actual_item_attributes))\n",
    "actual_scores_df['user']=actual_scores_df.index\n",
    "actual_scores_df.columns = cols + ['user'] \n",
    "all_recs = pd.wide_to_long(actual_scores_df, \"item_\", i=\"user\", j=\"item\").reset_index()\n",
    "all_recs.columns = ['user', 'item', 'score']\n",
    "\n",
    "all_recs=all_recs.sort_values(['user', 'score'], ascending=False)\n",
    "#all_recs[\"rank\"] = all_recs.groupby(\"user\")[\"score\"].rank(\"dense\", ascending=False)\n",
    "\n",
    "\n",
    "test_data = pd.DataFrame(mf.predicted_scores.value)\n",
    "test_data['user']=test_data.index\n",
    "test_data.columns = cols + ['user'] \n",
    "test_data = pd.wide_to_long(test_data, \"item_\", i=\"user\", j=\"item\").reset_index()\n",
    "test_data.columns = ['user', 'item', 'rating']\n",
    "#test_data=test_data.sort_values(['user', 'rating'], ascending=False)\n",
    "#test_data.head()\n",
    "\n",
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg)\n",
    "results = rla.compute(all_recs, test_data)\n",
    "\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.765192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.681182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.744136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.691402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.708399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.663785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.762712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.753711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.729181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.754841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.715968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.764383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.789776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.815302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.736857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.776270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.709947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.768209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.697160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.662274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.698745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.621940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.640741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.699921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.750839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.731790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.651852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.757372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.656436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.774422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nrecs      ndcg\n",
       "user                  \n",
       "0     1250.0  0.765192\n",
       "1     1250.0  0.681182\n",
       "2     1250.0  0.744136\n",
       "3     1250.0  0.691402\n",
       "4     1250.0  0.708399\n",
       "5     1250.0  0.663785\n",
       "6     1250.0  0.762712\n",
       "7     1250.0  0.753711\n",
       "8     1250.0  0.729181\n",
       "9     1250.0  0.754841\n",
       "10    1250.0  0.715968\n",
       "11    1250.0  0.764383\n",
       "12    1250.0  0.789776\n",
       "13    1250.0  0.815302\n",
       "14    1250.0  0.736857\n",
       "15    1250.0  0.776270\n",
       "16    1250.0  0.709947\n",
       "17    1250.0  0.768209\n",
       "18    1250.0  0.697160\n",
       "19    1250.0  0.662274\n",
       "20    1250.0  0.698745\n",
       "21    1250.0  0.621940\n",
       "22    1250.0  0.640741\n",
       "23    1250.0  0.699921\n",
       "24    1250.0  0.750839\n",
       "25    1250.0  0.731790\n",
       "26    1250.0  0.651852\n",
       "27    1250.0  0.757372\n",
       "28    1250.0  0.656436\n",
       "29    1250.0  0.774422"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_rla = topn.RecListAnalysis()\n",
    "mf_rla.add_metric(topn.ndcg)\n",
    "mf_results = rla.compute(all_recs, test_data)\n",
    "\n",
    "mf_results.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mflfd_metrics = pd.DataFrame(mflfd.get_measurements())\n",
    "mf_metrics = pd.DataFrame(mf.get_measurements())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_metrics.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(df1, df2, model1_lab, model2_lab, metric_var, ylab, title):\n",
    "    #mflfd_metrics = pd.DataFrame(mflfd.get_measurements())\n",
    "    metric1= df1[metric_var].to_list()[1:]\n",
    "\n",
    "    #mf_metrics = pd.DataFrame(mf.get_measurements())\n",
    "    metric2= df2[metric_var].to_list()[1:]\n",
    "    # style\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    # create a color palette\n",
    "    palette = plt.get_cmap('Set1')\n",
    "\n",
    "    plt.plot(list(range(len(metric1))), metric1, marker='', color=palette(0), linewidth=1, alpha=0.9, label=model1_lab)\n",
    "    plt.plot(list(range(len(metric2))), metric2, color=palette(1), linewidth=1, alpha=0.9, label=model2_lab)\n",
    "\n",
    "    # Add legend\n",
    "    #plt.legend(loc=2, ncol=2)\n",
    "    plt.legend(loc=1, ncol=1)\n",
    "\n",
    "    # Add titles\n",
    "    plt.title(title, loc='center', fontsize=16, fontweight=2)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(ylab)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(df1=mflfd_metrics, df2=mf_metrics, model1_lab='MF-LFD', model2_lab='MF-vanilla', \n",
    "            metric_var='interaction_similarity', ylab=\"Jaccard Index\", \n",
    "            title=\"Randomly Paired Users Interaction Similarity (Repeated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(df1=mflfd_metrics, df2=mf_metrics, model1_lab='MF-LFD', model2_lab='MF-vanilla', \n",
    "            metric_var='afsr', ylab=\"AFSR of Recs\", \n",
    "            title=\"AFSR of Recommendations (Repeated Training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(df1=mflfd_metrics, df2=mf_metrics, model1_lab='MF-LFD', model2_lab='MF-vanilla', \n",
    "            metric_var='shown_median_prediction', ylab=\"Median Predicted Value\", \n",
    "            title=\"Median Predicted Value of Recommendations (Repeated Training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(df1=mflfd_metrics, df2=mf_metrics, model1_lab='MF-LFD', model2_lab='MF-vanilla', \n",
    "            metric_var='interacted_median_prediction', ylab=\"Median Predicted Value\", \n",
    "            title=\"Median Predicted Value of Chosen Items (Repeated Training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(df1=mflfd_metrics, df2=mf_metrics, model1_lab='MF-LFD', model2_lab='MF-vanilla', \n",
    "            metric_var='mean_rec_distance', ylab=\"Mean Cosine Distance\", \n",
    "            title=\"Mean Distance b/w Recommended Items (Repeated Training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.predicted_scores.value[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf_mean = np.mean(mf.predicted_scores.value, axis=0)\n",
    "# plt.hist(mf_mean)\n",
    "# plt.show()\n",
    "\n",
    "# lfd_mean = np.mean(mflfd.predicted_scores.value, axis=0)\n",
    "# plt.hist(lfd_mean)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.scatter(np.array(mf.predicted_scores.value).flatten(), mf.actual_user_item_scores.flatten())\n",
    "# plt.xlabel(\"Predicted Scores\")\n",
    "# plt.ylabel(\"Actual Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsmall = MovieLens('../../MovieLens/data/ml-latest-small')\n",
    "ratings=mlsmall.ratings\n",
    "\n",
    "#make some fake interactions based on the ratings data\n",
    "ratings[\"interaction\"]=np.where(ratings[\"rating\"]>=4, 1, 0)\n",
    "ratings=ratings[ratings[\"interaction\"]==1]\n",
    "ratings = ratings[['user', 'item']]\n",
    "\n",
    "algo_als = als.ImplicitMF(10, iterations=100)\n",
    "algo_als.fit(ratings)\n",
    "preds_als = batch.predict(algo_als, mlsmall.ratings)\n",
    "#preds_als = pd.merge(preds_als, mlsmall.ratings, on=['user', 'item'])\n",
    "\n",
    "preds_als.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_als.head(30)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(preds_als[\"prediction\"], preds_als[\"rating\"], s=1)\n",
    "plt.xlabel(\"Predicted Interaction Scores\")\n",
    "plt.ylabel(\"Actual Rating Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_item_features = pd.DataFrame(als.item_features_)\n",
    "mflfd_item_features = pd.DataFrame(mflfd.items_hat.T)\n",
    "#mflfd_item_features.head()\n",
    "\n",
    "mf_item_features = pd.DataFrame(mf.items_hat.T)\n",
    "#mf_item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_features(features_df, model_type, color='blue'):\n",
    "    font = {'family' : 'normal',\n",
    "            'weight' : 'bold',\n",
    "            'size'   : 12}\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    n_features = list(range(0,10))\n",
    "    fig, axs = plt.subplots(math.ceil(len(n_features)/3), 3, figsize=(20,20))\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                        wspace=0.35)\n",
    "    fig.suptitle('Latent Factors for {}'.format(model_type), size=20)\n",
    "\n",
    "    for idx, n_feature in enumerate(n_features):\n",
    "        r=idx //3\n",
    "        c=idx % 3\n",
    "\n",
    "        #hat = features_df[n_feature].tolist()\n",
    "        features = features_df[n_feature].tolist()\n",
    "        axs[r, c].set_title('Factor {}'.format(n_feature))\n",
    "\n",
    "        #axs[r,c].plot(hat, actual, 'o', color=color);\n",
    "        axs[r,c].hist(features, color=color)\n",
    "\n",
    "    #for ax in axs.flat:\n",
    "    #    ax.set(xlabel='hat representation', ylabel='actual representation')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    #for ax in axs.flat:\n",
    "    #    ax.label_outer()\n",
    "\n",
    "    fig.delaxes(axs[3][1])\n",
    "    fig.delaxes(axs[3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(als_item_features, 'MovieLens MF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(mflfd_item_features, 'MF-LFD', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_features(mf_item_features, 'MF', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd.predicted_scores.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_predicted_std = np.std(predicted_rec_vals)\n",
    "median_predicted_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_representation = Generator().binomial(\n",
    "#     n=1, p=.3, size=(NUM_USERS, N_FACTORS)\n",
    "# )\n",
    "\n",
    "# item_representation = Generator().binomial(\n",
    "#     n=1, p=.3, size=(N_FACTORS, NUM_ITEMS)\n",
    "# )\n",
    "# # Initialize with custom representations\n",
    "# filtering = ContentFiltering(user_representation=user_representation,\n",
    "#                             item_representation=item_representation)\n",
    "\n",
    "# filtering.add_metrics(AverageFeatureScoreRange())\n",
    "# filtering.run(10)\n",
    "\n",
    "# filtering.get_measurements()\n",
    "#u = ChaneyUsers(np.copy(known_scores), size=(NUM_USERS, NUM_ATTRS), num_users=NUM_USERS, attention_exp=ATTENTION_EXP, repeat_items=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_item_predictions = mflfd.predicted_scores.value[:, mflfd.rec]\n",
    "recommended_item_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.all_interactions.sort_values('user').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_test = ImplicitMF(num_users=10, num_items=100, num_latent_factors=N_FACTORS, num_items_per_iter=10,\n",
    "                model_params=model_params)\n",
    "#mf.add_metrics(MSEMeasurement())\n",
    "#mf.add_metrics(AverageFeatureScoreRange())\n",
    "#mf.add_metrics(RecSimilarity(pairs=js_pairs))\n",
    "mf_test.add_metrics(ShownMedianPrediction())\n",
    "mf_test.add_metrics(InteractedMedianPrediction())\n",
    "mf_test.add_metrics(MeanRecDistance())\n",
    "mf_test.add_state_variable(mf.predicted_scores)\n",
    "#mf_test.add_state_variable(mf.users.actual_user_scores)\n",
    "mf_test.startup_and_train(NUM_STARTUP)\n",
    "mf_test.run(timesteps=NUM_STEPS, train_between_steps=True, reset_interactions=False)\n",
    "#mf.run(timesteps=NUM_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_test_metrics = pd.DataFrame(mf_test.get_measurements())\n",
    "mf_test_metrics.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mf_scores = pd.DataFrame(mf.predicted_scores.value)\n",
    "# cols = [f\"item_{c}\" for c in mf_scores.columns]\n",
    "# mf_scores.columns = cols\n",
    "# #mf_scores.head()\n",
    "# mf_scores[\"user\"] = list(range(mf_scores.shape[0]))\n",
    "\n",
    "\n",
    "# # t=pd.wide_to_long(mf_scores, \"item_\", i=\"user\", j=\"item\").reset_index()\n",
    "# # t.columns = [\"user\", \"item\", \"predicted_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_step_len = len(str(NUM_STEPS + NUM_STARTUP))\n",
    "\n",
    "for t in range(NUM_STEPS + NUM_STARTUP):\n",
    "\n",
    "    X=mf.predicted_scores.state_history[t].flatten()\n",
    "    Y=mf.users.actual_user_scores.state_history[t].flatten()\n",
    "\n",
    "    # plt.scatter(X, Y)\n",
    "    # plt.figure(figsize=(15, 15))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    fig.set_tight_layout(True)\n",
    "    ax.set(xlim=(-5, 5), ylim=(-5, 5))\n",
    "    ax.set_xlabel(\"Predicted Score\")\n",
    "    ax.set_ylabel(\"Actual Score\")\n",
    "    ax.scatter(X,Y, s=1, alpha=.7)\n",
    "    \n",
    "    step_len=len(str(t))\n",
    "    \n",
    "    num_leading_zeros = final_step_len-step_len\n",
    "    \n",
    "    ext=str('0'*num_leading_zeros) + str(t)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Save it & close the figure\n",
    "    filename='/Users/amywinecoff/Documents/CITP/Research/Github/scatters/mf/scatter_step'+ext+'.png'\n",
    "    plt.savefig(fname=filename, dpi=96)\n",
    "    plt.gca()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "os.chdir('/Users/amywinecoff/Documents/CITP/Research/Github/scatters/mf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert -delay 20 scatter*.png animated_scatter_mf.gif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
