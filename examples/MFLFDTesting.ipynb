{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import trecs\n",
    "from trecs.models import ImplicitMF, ImplicitMFLFD\n",
    "from trecs.random import Generator\n",
    "from trecs.metrics import MSEMeasurement, AverageFeatureScoreRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 584.67it/s]\n"
     ]
    }
   ],
   "source": [
    "mf = ImplicitMF(num_users=200, num_items=50, num_latent_factors=20)\n",
    "mf.add_metrics(MSEMeasurement())\n",
    "mf.startup_and_train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd = ImplicitMFLFD(num_users=200, num_items=50, num_latent_factors=20)\n",
    "mflfd.add_metrics(MSEMeasurement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 503.29it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 234.43it/s]\n"
     ]
    }
   ],
   "source": [
    "mflfd.startup_and_train(20)\n",
    "mflfd.run(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43, 14,  3, ..., 17, 13, 44],\n",
       "       [13,  2, 25, ...,  4,  0,  9],\n",
       "       [39, 13, 42, ..., 26, 15,  5],\n",
       "       ...,\n",
       "       [ 4,  7, 25, ..., 23, 45, 46],\n",
       "       [13, 22, 44, ..., 35,  9, 15],\n",
       "       [18, 13, 35, ..., 22, 47, 17]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.item_indices[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictedScores([[-0.06273281,  0.06886859, -0.00567519, ...,\n",
       "                   0.05445335,  0.02260769,  0.05934655],\n",
       "                 [ 0.12988215, -0.0346267 ,  0.24468186, ...,\n",
       "                   0.10893789,  0.05290764,  0.00351817],\n",
       "                 [ 0.04296566,  0.16896895,  0.06580345, ...,\n",
       "                   0.05888834, -0.04893276,  0.09713374],\n",
       "                 ...,\n",
       "                 [ 0.25171803, -0.01905507,  0.04780995, ...,\n",
       "                   0.03291001,  0.0211827 ,  0.24986726],\n",
       "                 [-0.05419834,  0.2483475 ,  0.03768484, ...,\n",
       "                   0.06427463, -0.00132529, -0.06175335],\n",
       "                 [ 0.18482815,  0.19309881,  0.17933266, ...,\n",
       "                   0.19003587, -0.01764408,  0.07171722]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_limit=25\n",
    "k=10\n",
    "\n",
    "row = np.repeat(mflfd.users.user_vector, mflfd.item_indices.shape[1])\n",
    "row = row.reshape((mflfd.num_users, -1))\n",
    "s_filtered = mflfd.predicted_scores[row, mflfd.item_indices]\n",
    "\n",
    "negated_scores = -1 * s_filtered  # negate scores so indices go from highest to lowest\n",
    "# break ties using a random score component\n",
    "scores_tiebreak = np.zeros(\n",
    "    negated_scores.shape, dtype=[(\"score\", \"f8\"), (\"random\", \"f8\")]\n",
    ")\n",
    "scores_tiebreak[\"score\"] = negated_scores\n",
    "scores_tiebreak[\"random\"] = mflfd.random_state.random(negated_scores.shape)\n",
    "top_k = scores_tiebreak.argpartition(top_n_limit - 1, order=[\"score\", \"random\"])[:, :top_n_limit]\n",
    "# now we sort within the top k\n",
    "row = np.repeat(mflfd.users.user_vector, top_n_limit).reshape((mflfd.num_users, -1))\n",
    "# again, indices should go from highest to lowest\n",
    "sort_top_k = scores_tiebreak[row, top_k].argsort(order=[\"score\", \"random\"])\n",
    "top_k_recs = mflfd.item_indices[row, top_k[row, sort_top_k]]\n",
    "\n",
    "#dims are attribute, items, users\n",
    "top_k_att = mflfd.items_hat[:, top_k_recs[:]].swapaxes(1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f60ae8fabc64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#test=s_filtered[row, top_k_recs]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop_k_recs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'user' is not defined"
     ]
    }
   ],
   "source": [
    "#test=s_filtered[row, top_k_recs]\n",
    "#top_k_recs[user, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mflfd.items_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 25)\n",
      "(20, 25, 200)\n"
     ]
    }
   ],
   "source": [
    "print(top_k_recs.shape)\n",
    "print(top_k_att.shape)\n",
    "#items_att_filt.swapaxes(1,2)\n",
    "#items_att_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'items_att_filt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5de9adf5bf1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_item_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems_att_filt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop_item_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_k_recs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k_recs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'items_att_filt' is not defined"
     ]
    }
   ],
   "source": [
    "top_item_att = items_att_filt[:,0, :]\n",
    "top_item_idx = top_k_recs[:, 0].reshape(top_k_recs.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_item_att.shape, top_item_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflfd.items_hat[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_recs_idx = np.empty([mflfd.users_hat.shape[0], k])\n",
    "# print(all_recs_idx.shape)\n",
    "# print(top_item_idx.shape)\n",
    "# all_recs[:, 0] = top_item_idx[:,None]\n",
    "all_recs_idx = top_k_recs[:,0].reshape(top_k_recs.shape[0],1)\n",
    "top_k_recs[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.81143934 1.81143934 1.81143934 1.81143934\n",
      "  1.81143934 1.81143934 1.81143934 1.81143934 2.47148637 2.60064601\n",
      "  2.3076651  2.70420452 2.46666648 2.6302484  2.82266898 2.61939773\n",
      "  3.60247272 2.79575144 3.01711994 2.45088035 2.46843064 3.18906196\n",
      "  2.82072745]]\n",
      "18 18 3.602472721277783\n"
     ]
    }
   ],
   "source": [
    "#store the id of the highest predicted item for each user as a start\n",
    "all_recs_idx = top_k_recs[:,0].reshape(top_k_recs.shape[0],1)\n",
    "for idx, user in enumerate(mflfd.users_hat):\n",
    "\n",
    "        #get the top rec and add that as the first item for each user\n",
    "        user_item_feats = top_k_att[:,:,idx]\n",
    "        orig_user_item_feats = user_item_feats\n",
    "        #user_item_feats_idx = [0]\n",
    "        user_max_idx = top_k_recs[idx, 0] \n",
    "        recs_idxs = [user_max_idx]\n",
    "        \n",
    "        #hold the features of the recommended items\n",
    "        recs_features = mflfd.items_hat[:,user_max_idx]\n",
    "        \n",
    "        distances = []\n",
    "        \n",
    "        for rec in range(1,k):\n",
    "            \n",
    "            #user_item_feats_idx.append(rec)\n",
    "            \n",
    "            #drop element from user_item_feats that has been put in the recommendations\n",
    "            ##DONT DO THIS BECAUSE IT MAKES INDEXING MORE COMPLEX\n",
    "            #mask = np.invert(np.isin(user_item_feats, recs_features))\n",
    "            #user_item_feats = user_item_feats[mask].reshape(user_item_feats.shape[0], -1).shape\n",
    "            \n",
    "            if rec == 1:\n",
    "                #for the second item, just use the first item values\n",
    "                centroid = recs_features\n",
    "            else:\n",
    "                centroid = np.nanmean(recs_features, axis=0)\n",
    "\n",
    "            centroid = centroid.reshape(1, -1)\n",
    "\n",
    "            #set all the previously chosen item features to the centroid, so they will not be selected again\n",
    "            #don't want to just remove rows because it will throw of the indexing\n",
    "            user_item_feats[:, 0:rec+1]=centroid.T\n",
    "\n",
    "            d = pairwise_distances(X=centroid, Y=user_item_feats.T, metric='cityblock',force_all_finite='allow_nan' )\n",
    "            \n",
    "            most_distant = np.argmax(d)\n",
    "            \n",
    "            if rec == 1 and idx == 199:\n",
    "                #print()\n",
    "                print(d)\n",
    "                print (user_max_idx, most_distant, d.max())\n",
    "            \n",
    "            distances.append(d.max())\n",
    "            \n",
    "            most_distant_feats = user_item_feats.T[most_distant]\n",
    "            \n",
    "            #get the index of the most distant item in the top k recs\n",
    "            recs_idxs.append(top_k_recs[idx, most_distant])\n",
    "            #recs_idxs.append(most_distant)\n",
    "            #get the item index from the original array of indices, not the constrained array\n",
    "            #orig_recs_idxs.append(top_k_recs[idx, most_distant])\n",
    "            #recs_preds.append(n_ratings[idx][most_distant])\n",
    "\n",
    "            recs_features = np.vstack((recs_features, user_item_feats[:, most_distant]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.81143934 1.81143934 1.81143934 1.81143934 1.81143934 1.81143934\n",
      "  1.81143934 1.81143934 1.81143934 1.81143934 2.47148637 2.60064601\n",
      "  2.3076651  2.70420452 2.46666648 2.6302484  2.82266898 2.61939773\n",
      "  3.60247272 2.79575144 3.01711994 2.45088035 2.46843064 3.18906196\n",
      "  2.82072745]]\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.81143934 1.81143934 1.81143934 1.81143934 1.81143934 1.81143934\n",
      "  1.81143934 1.81143934 1.81143934 1.81143934 2.47148637 2.60064601\n",
      "  2.3076651  2.70420452 2.46666648 2.6302484  2.82266898 2.61939773\n",
      "  3.60247272 2.79575144 3.01711994 2.45088035 2.46843064 3.18906196\n",
      "  2.82072745]]\n"
     ]
    }
   ],
   "source": [
    "test=mflfd.items_hat[:,user_max_idx].reshape(1, -1)\n",
    "#print(test.shape)\n",
    "d = pairwise_distances(X=test, Y=orig_user_item_feats.T, metric='cityblock',force_all_finite='allow_nan' )\n",
    "print(d)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_att.shape\n",
    "last_user_att = top_k_att[:,:,199]\n",
    "#print(recs_idxs)\n",
    "#print(distances)\n",
    "last_user_att.shape\n",
    "top_k_recs[199,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#distance.cityblock(mflfd.items_hat[18], mflfd.items_hat[9])\n",
    "\n",
    "all_ds = pairwise_distances(X=last_user_att[18].reshape(1, -1), Y=last_user_att, metric='cityblock',force_all_finite='allow_nan' )\n",
    "all_ds.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.148073029217128"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ds[18].max()\n",
    "#top_k_recs\n",
    "#user_max_idx = top_k_recs[idx, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 24)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(user_item_feats, recs_features)\n",
    "mask = np.invert(np.isin(user_item_feats, recs_features))\n",
    "#mask.shape\n",
    "#result = user_item_feats[mask,...]\n",
    "\n",
    "#drop element from user_item_feats that has been put in the recommendations\n",
    "user_item_feats = user_item_feats[mask].reshape(user_item_feats.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 25)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_feats.shape\n",
    "#C = np.delete(C, 1, 1)  # delete second column of C\n",
    "#np.where(np.isin(user_item_feats, recs_features), user_item_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 43 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4bfa51b4e100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_item_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecs_idxs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#mask[[0,2,4]] = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 43 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "mask = np.ones(shape=user_item_feats.shape, dtype=bool)\n",
    "mask[recs_idxs] = False\n",
    "\n",
    "#mask[[0,2,4]] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_factors_diversification(user_features, item_features, n_recs=10, top_n_limit=None):\n",
    "\n",
    "\n",
    "    hat_ratings = np.dot(user_features, item_features.T) \n",
    "\n",
    "    if top_n_limit:\n",
    "        #if constraining by top n, only retain the top n ratings within each user\n",
    "        ind=np.argpartition(hat_ratings,-top_n_limit)[:,-top_n_limit:]\n",
    "        n_ratings = np.take(hat_ratings, ind)\n",
    "    else:\n",
    "        #if not constraining by top n, retail all item indices for all users. \n",
    "        #If this is the case, in all_user_recs, recs_idxs should match original_recs_idxs\n",
    "        ind=np.tile(np.arange(0,len(item_features)),(len(user_features),1))\n",
    "        n_ratings = hat_ratings\n",
    "\n",
    "\n",
    "\n",
    "    all_user_recs = dict()\n",
    "    \n",
    "    max_idx = np.argmax(n_ratings, axis=1)\n",
    "    top_items=item_features[max_idx]\n",
    "    \n",
    "    all_recs = np.empty([user_features.shape[0],item_features.shape[1], n_recs])\n",
    "    #all_recs = None\n",
    "    \n",
    "\n",
    "    for idx, user in enumerate(user_features):\n",
    "\n",
    "        user_item_feats = item_features[ind[idx]]\n",
    "        user_max_idx = np.argmax(n_ratings[idx])\n",
    "\n",
    "        #get the top rec and add that as the first item for each user\n",
    "        user_max = max_idx[idx]\n",
    "        recs_features = top_items[idx]\n",
    "        recs_idxs = [max_idx[idx]]\n",
    "        recs_preds = [n_ratings[idx][user_max]]\n",
    "        orig_recs_idxs = [ind[idx, user_max]]\n",
    "\n",
    "\n",
    "\n",
    "        for rec in range(1,n_recs):\n",
    "            if rec == 1:\n",
    "                #for the second item, just use the first item values\n",
    "                centroid = recs_features\n",
    "            else:\n",
    "                centroid = np.nanmean(recs_features, axis=0)\n",
    "\n",
    "            centroid = centroid.reshape(1, -1)\n",
    "\n",
    "            #set all the previously chosen item features to the centroid, so they will not be selected again\n",
    "            #don't want to just remove rows because it will throw of the indexing\n",
    "            user_item_feats[recs_idxs]=centroid\n",
    "\n",
    "            d = pairwise_distances(X=centroid, Y=user_item_feats, metric='cityblock',force_all_finite='allow_nan' )\n",
    "            most_distant = np.argmax(d)\n",
    "\n",
    "            recs_idxs.append(most_distant)\n",
    "            #get the item index from the original array of indices, not the constrained array\n",
    "            orig_recs_idxs.append(ind[idx, most_distant])\n",
    "            recs_preds.append(n_ratings[idx][most_distant])\n",
    "\n",
    "            recs_features = np.vstack((recs_features, user_item_feats[most_distant]))\n",
    "\n",
    "        all_recs[idx, :, :]=recs_features\n",
    "            \n",
    "        all_user_recs[idx]={'user_feats': user,\n",
    "                        'original_recs_idx':orig_recs_idxs,\n",
    "                        'recs_idx':recs_idxs,\n",
    "                        'recs_features':recs_features,\n",
    "                        'recs_preds':recs_preds}\n",
    "\n",
    "        \n",
    "    return all_recs, all_user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "print(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trecsEnv",
   "language": "python",
   "name": "trecsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
